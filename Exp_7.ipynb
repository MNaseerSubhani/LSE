{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQrj7wcIQqHG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from options.train_options import TrainOptions\n",
    "from options.test_options import TestOptions\n",
    "import os\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from data import CreateSrcDataLoader\n",
    "from data import CreateTrgDataLoader\n",
    "from model import CreateModel\n",
    "# from model import CreateDiscriminator\n",
    "from utils.timer import Timer\n",
    "import tensorboardX\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from IPython.display import clear_output\n",
    "# import evaluation\n",
    "import os.path as osp\n",
    "import collections\n",
    "from torch.utils import data\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import time\n",
    "import run_time_evaluation\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LSLRr4KNQqHN"
   },
   "source": [
    "\n",
    "Init settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L_LqItd0QqHO"
   },
   "outputs": [],
   "source": [
    "root_base = '/home/olektra_gpu/Desktop/olektra projects/ECCV'                   #Root directory\n",
    "sorted_list = root_base +'/dataset/cityscapes_list/sorted.txt'         # Final sorted list's path\n",
    "data_gen_list = root_base +'/dataset/cityscapes_list/data_gen_list.txt'# data generated list's path\n",
    "generated_data = root_base +'/dataset/generated_data/'                 # generated data path\n",
    "generated_data_path = root_base +\"/dataset/generated_data/\"\n",
    "\n",
    "\n",
    "select_model = 'DeepLab'                                                   # 'VGG' or 'DeepLab'\n",
    "source_data = 'synthia'                                                   # 'synthia' or 'gta5'\n",
    "model_pick = 'init'                                                    #'init' or 'annex'\n",
    "model_weights = 'syn_2_city_deeplab'                                 # weights file's name\n",
    "\n",
    "\n",
    "IMG_W = 1024                                                           #Image width\n",
    "IMG_H = 512                                                            #Image height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2h7MsZNQqHT"
   },
   "outputs": [],
   "source": [
    "eval_list = root_base +'/dataset/cityscapes_list/eval_.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJz5H6Y8QqHX"
   },
   "source": [
    "# Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oD233fo3QqHZ"
   },
   "outputs": [],
   "source": [
    "file_name_save = root_base + '/snapshots/mIoU.txt'\n",
    "def print_args(args):\n",
    "    message = ''\n",
    "    message += '----------------- Options ---------------\\n'\n",
    "    for k, v in sorted(vars(args).items()):\n",
    "        comment = ''\n",
    "        message += '{:>25}: {:<30}{}\\n'.format(str(k), str(v), comment)\n",
    "    message += '--------------------------------------'\n",
    "   \n",
    "\n",
    "    # save to the disk\n",
    "    \n",
    "    with open(file_name_save, 'a') as args_file:\n",
    "        args_file.write(message)\n",
    "        args_file.write('\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8BMOirKFQqHd"
   },
   "outputs": [],
   "source": [
    "\n",
    "def change_args(args):\n",
    "    args.model =select_model\n",
    "    args.source=source_data\n",
    "    args.data_dir=root_base + '/dataset/'+args.source\n",
    "    args.data_list = root_base+'/dataset/'+args.source+'_list/train.txt'\n",
    "    args.data_list_target = root_base +'/dataset/cityscapes_list/train.txt'\n",
    "    args.restore_from   = root_base + '/init_models/' + model_pick+ '/' + model_weights   #init_weights\n",
    "    args.batch_size = 1\n",
    "    args.weight_decay = 0.0005\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vX_YDSVSQqHj"
   },
   "outputs": [],
   "source": [
    "classes = ['road' , 'side walk', 'building' , 'wall', 'fence', 'pole', 'trafic lights', 'trafic sign', 'vegitation', 'terrain', 'sky', 'person', 'rider', 'car', 'truck','bus', 'train', 'motorcycle', 'bicycle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGqfuCH7QqHn"
   },
   "outputs": [],
   "source": [
    "def keras_out(inp):\n",
    "    inp = np.rollaxis(inp,axis =-1)\n",
    "    inp = np.rollaxis(inp,axis =-1)\n",
    "    inp = inp.reshape(1,inp.shape[0],inp.shape[1],inp.shape[2])\n",
    "    \n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9L_pUw6QqHr"
   },
   "outputs": [],
   "source": [
    "def Plot_img(out):\n",
    "    plt.imshow(out.reshape(IMG_H,IMG_W,3),interpolation='nearest')\n",
    "    plt.grid(False)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9iChmTptQqHv"
   },
   "outputs": [],
   "source": [
    "def self_entropy(pred, epsilon=1e-12):\n",
    "    pred = pred[0]\n",
    "    p = pred * np.log(pred+ epsilon)\n",
    "    map_ = -np.sum(p, -1)\n",
    "    \n",
    "    return map_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6rRzgu2QqH0"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Load areas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3253,
     "status": "ok",
     "timestamp": 1581505345641,
     "user": {
      "displayName": "Muhammad Naseer Subhani",
      "photoUrl": "",
      "userId": "06699857406068047110"
     },
     "user_tz": -300
    },
    "id": "orupHvbzQqH2",
    "outputId": "bb82a0a0-159d-4b3f-fe7c-eace551f845f"
   },
   "outputs": [],
   "source": [
    "# area_save_path = root_base + \"/areas_and_spatial_priors/area_classes_s.npy\"\n",
    "# class_mArea_man = np.load(area_save_path)\n",
    "# arr=np.ones((19))\n",
    "# arr[0:19] = class_mArea_man\n",
    "# weights =  (arr)\n",
    "# weight_mat = np.zeros((512,1024,19))\n",
    "# for i in range(512):\n",
    "#     for j in range(1024):\n",
    "#         weight_mat[i][j] = weights\n",
    "        \n",
    "# weight_mat = np.rollaxis(weight_mat,axis = -1)\n",
    "# print(weight_mat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3162,
     "status": "ok",
     "timestamp": 1581505345643,
     "user": {
      "displayName": "Muhammad Naseer Subhani",
      "photoUrl": "",
      "userId": "06699857406068047110"
     },
     "user_tz": -300
    },
    "id": "aKryf5cNQqH5",
    "outputId": "ae2e653b-4cf8-4353-b128-878c7ccc0471"
   },
   "outputs": [],
   "source": [
    "# weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YN0fpZBaQqH-"
   },
   "source": [
    "Load priors of source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AhWQMiuoQqH_"
   },
   "outputs": [],
   "source": [
    "# save_pth = root_base + \"/priors_of_source/priors_gta5.npy\"\n",
    "# priors_ = np.load(save_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O2oexeRvQqIC"
   },
   "outputs": [],
   "source": [
    "# priors__ = resize(priors_, (19,1024, 2048), anti_aliasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJSZ910PQqIG"
   },
   "outputs": [],
   "source": [
    "# from scipy.ndimage.filters import gaussian_filter\n",
    "# source_priros= np.zeros((19,1024,2048))\n",
    "# for j in range(19):\n",
    "    \n",
    "#     source_priros[j] = gaussian_filter(priors__[j], sigma=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WzxLGvvWQqIJ"
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize = (5,4))\n",
    "# columns = 5\n",
    "# rows = 4\n",
    "\n",
    "# for i in range(1, columns * rows ):\n",
    "#     fig.add_subplot(rows, columns, i)\n",
    "#     fig.set_size_inches(18.5,10.5)\n",
    "#     plt.imshow(source_priros[i-1],interpolation = 'nearest')\n",
    "#     plt.grid(False)\n",
    "#     plt.title(classes[i-1])\n",
    "    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W2RNiWGQQqIN"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTE_nj2iQqIN"
   },
   "outputs": [],
   "source": [
    "def ent_normalization(SE,Y_pre):\n",
    "    tY_pre = Y_pre[0,:,:,:]\n",
    "    labs = np.argmax(tY_pre, axis=-1)\n",
    "    labs1 = labs.flatten()\n",
    "    se1 = SE.flatten()\n",
    "\n",
    "    uniq = np.unique(labs1)\n",
    "\n",
    "    for un in range(uniq.shape[0]):\n",
    "\n",
    "        t_se = se1[labs1==uniq[un]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        t_se1 = (t_se - t_se.min() )/(t_se.max()-t_se.min() )\n",
    "\n",
    "        se1[labs1==uniq[un]] = t_se1\n",
    "\n",
    "    SE = se1.reshape(SE.shape)\n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAerP0MOQqIQ"
   },
   "outputs": [],
   "source": [
    "class model_init():\n",
    "    def __init__(self):\n",
    "        opt = TrainOptions()\n",
    "        args = opt.initialize()\n",
    "        \n",
    "        \n",
    "        change_args(args)\n",
    "        _t = {'iter time' : Timer()}\n",
    "        model_name = args.source + '_to_' + args.target\n",
    "\n",
    "        if not os.path.exists(args.snapshot_dir):\n",
    "            os.makedirs(args.snapshot_dir)   \n",
    "            os.makedirs(os.path.join(args.snapshot_dir, 'logs'))\n",
    "  \n",
    "        \n",
    "        \n",
    "        model, optimizer = CreateModel(args)\n",
    " \n",
    "\n",
    "        self.args =args\n",
    "        self.model_name =model_name\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.opt = opt\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_mcOzbAQqIU"
   },
   "outputs": [],
   "source": [
    "IMG_MEAN = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0brE1hDQqIY"
   },
   "outputs": [],
   "source": [
    "def load_single_image(name):\n",
    "    \n",
    "    image = Image.open(osp.join(root_base + '/dataset/cityscapes/', \"leftImg8bit/%s/%s\" % ('train', name))).convert('RGB')\n",
    "    # resize\n",
    "    image = image.resize((IMG_W,IMG_H), Image.BICUBIC)\n",
    "\n",
    "    rl_image = np.asarray(image, np.float32)\n",
    "    rl_image_rgb = rl_image.copy()\n",
    "\n",
    "\n",
    "    size = rl_image.shape\n",
    "    image = rl_image[:, :, ::-1]  # change to BGR\n",
    "    image -= IMG_MEAN\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    \n",
    "\n",
    "    return image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3PXeESIQqIb"
   },
   "outputs": [],
   "source": [
    "\n",
    "epsilon = 1e-12\n",
    "cnt_img =0\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class Base_Adaptation():\n",
    "    def __init__(self,model_loader):\n",
    "        self.args =model_loader.args\n",
    "        self.model_name =model_loader.model_name\n",
    "        self.model = model_loader.model\n",
    "        self.optimizer = model_loader.optimizer\n",
    "        self.cnt_img = 0\n",
    "        self.entropy_th_class = np.ones((1,19)) #* self.args.entropy_th\n",
    "        \n",
    "    def sorting(self):\n",
    "        print(\"*********** Finding most confident samples using\",self.args.sorting_method,\" ***********\")\n",
    "        if(self.args.sorting_method == 'class_wise'):\n",
    "            self.class_wise_sort()\n",
    "        else:\n",
    "            self.global_sort()\n",
    "        print(\"***************END********************\")\n",
    "            \n",
    "            \n",
    "    \n",
    "    def class_wise_sort(self):\n",
    "        self.args.data_label_folder_target = None \n",
    "        self.args.shuffel_ = False\n",
    "        self.args.data_dir_target = root_base +'/dataset/cityscapes'\n",
    "        self.args.data_list_target = root_base +'/dataset/cityscapes_list/train.txt'\n",
    "        self.args.num_steps = self.args.total_no_of_target\n",
    "        self.args.batch_size = 1\n",
    "        self.model.eval()\n",
    "        self.model.cuda()    \n",
    "        targetloader = CreateTrgDataLoader(self.args)\n",
    "        \n",
    "        data_save_class = {classes[0]:[],classes[1]:[],classes[2]:[],classes[3]:[],classes[4]:[],classes[5]:[],classes[6]:[],classes[7]:[],classes[8]:[],classes[9]:[],classes[10]:[],classes[11]:[],classes[12]:[],classes[13]:[],classes[14]:[],classes[15]:[],classes[16]:[],classes[17]:[],classes[18]:[],\"f_name_\"+classes[0]:[],\"f_name_\"+classes[1]:[],\"f_name_\"+classes[2]:[],\"f_name_\"+classes[3]:[],\"f_name_\"+classes[4]:[],\"f_name_\"+classes[5]:[],\"f_name_\"+classes[6]:[],\"f_name_\"+classes[7]:[],\"f_name_\"+classes[8]:[],\"f_name_\"+classes[9]:[],\"f_name_\"+classes[10]:[],\"f_name_\"+classes[11]:[],\"f_name_\"+classes[12]:[],\"f_name_\"+classes[13]:[],\"f_name_\"+classes[14]:[],\"f_name_\"+classes[15]:[],\"f_name_\"+classes[16]:[],\"f_name_\"+classes[17]:[],\"f_name_\"+classes[18]:[]}\n",
    "        data_save_class_sorted = {classes[0]:[],classes[1]:[],classes[2]:[],classes[3]:[],classes[4]:[],classes[5]:[],classes[6]:[],classes[7]:[],classes[8]:[],classes[9]:[],classes[10]:[],classes[11]:[],classes[12]:[],classes[13]:[],classes[14]:[],classes[15]:[],classes[16]:[],classes[17]:[],classes[18]:[],\"f_name_\"+classes[0]:[],\"f_name_\"+classes[1]:[],\"f_name_\"+classes[2]:[],\"f_name_\"+classes[3]:[],\"f_name_\"+classes[4]:[],\"f_name_\"+classes[5]:[],\"f_name_\"+classes[6]:[],\"f_name_\"+classes[7]:[],\"f_name_\"+classes[8]:[],\"f_name_\"+classes[9]:[],\"f_name_\"+classes[10]:[],\"f_name_\"+classes[11]:[],\"f_name_\"+classes[12]:[],\"f_name_\"+classes[13]:[],\"f_name_\"+classes[14]:[],\"f_name_\"+classes[15]:[],\"f_name_\"+classes[16]:[],\"f_name_\"+classes[17]:[],\"f_name_\"+classes[18]:[]}\n",
    "    \n",
    "        \n",
    "        \n",
    "        for index, batch in tqdm.tqdm(enumerate(targetloader)):\n",
    "            \n",
    "            image, _, name ,__= batch\n",
    "            fn = name[0]\n",
    "            output = self.model(Variable(image).cuda())\n",
    "            output = nn.functional.softmax(output, dim=1)\n",
    "            output=output.cpu().data[0].numpy()\n",
    "            y_pred = keras_out(output)\n",
    "            \n",
    "            \n",
    "            \n",
    "            MP_max = np.max(y_pred,axis = -1)[0]\n",
    "            LP_argmax = np.argmax(y_pred,axis = -1)[0]\n",
    "            \n",
    "      \n",
    "            for c in range(len(classes) ):\n",
    "                M_c = MP_max[LP_argmax == c]\n",
    "                if(M_c.any()):\n",
    "                    data_save_class['f_name_'+classes[c]].append(fn)\n",
    "                    data_save_class[classes[c]].append(np.mean(M_c))\n",
    "        \n",
    "\n",
    "        f = open(sorted_list,\"w+\") \n",
    "        f_ev = open(eval_list,\"w+\") \n",
    "        self.cnt_img=0\n",
    "        over_all_list = []\n",
    "        for c in range(len(classes) ):      \n",
    "            \n",
    "            if(source_data == 'synthia'):\n",
    "                if(c !=9 and c !=14 and c !=16):\n",
    "                    max_prob_sorted_ascending, f_name_arrays = zip(*sorted(zip(data_save_class[classes[c]], data_save_class['f_name_'+classes[c]])))\n",
    "                    f_name_arrays = f_name_arrays[::-1]\n",
    "                    max_prob_sorted_ascending = max_prob_sorted_ascending[::-1]\n",
    "\n",
    "                    data_save_class_sorted[classes[c]] = max_prob_sorted_ascending\n",
    "                    data_save_class_sorted['f_name_'+classes[c]] = f_name_arrays\n",
    "                    select_imgs =  int(len(f_name_arrays) * (self.args.p/19))\n",
    "\n",
    "                    selct = f_name_arrays[0:select_imgs]\n",
    "\n",
    "\n",
    "\n",
    "                    ######Dynamic threshold of each class##############\n",
    "\n",
    "                    f_n = f_name_arrays[select_imgs]\n",
    "                    img= load_single_image(f_n)\n",
    "                    img = img.reshape(1,3,IMG_H,IMG_W)\n",
    "                    img = torch.from_numpy(img).float().to(device)\n",
    "                    out_ = self.model(Variable(img).cuda())\n",
    "                    out_ = nn.functional.softmax(out_, dim=1)\n",
    "                    out_=out_.cpu().data[0].numpy()\n",
    "                    y_pred = keras_out(out_)\n",
    "\n",
    "\n",
    "                    Y_argmax = np.argmax(y_pred,axis = -1)[0]\n",
    "                    SE_main = self_entropy(y_pred)\n",
    "\n",
    "                    if(self.args.entropy_normalization):\n",
    "                        SE_main = ent_normalization(SE_main,y_pred)\n",
    "\n",
    "                    class_se = SE_main[Y_argmax == c]\n",
    "                    mean_class_se = np.mean(class_se) * self.args.ent_th_on_class_gain\n",
    "\n",
    "\n",
    "                    self.entropy_th_class[0][c] = mean_class_se\n",
    "\n",
    "                    ##############################################\n",
    "\n",
    "                    over_all_list += selct\n",
    "            else:\n",
    "                max_prob_sorted_ascending, f_name_arrays = zip(*sorted(zip(data_save_class[classes[c]], data_save_class['f_name_'+classes[c]])))\n",
    "                f_name_arrays = f_name_arrays[::-1]\n",
    "                max_prob_sorted_ascending = max_prob_sorted_ascending[::-1]\n",
    "\n",
    "                data_save_class_sorted[classes[c]] = max_prob_sorted_ascending\n",
    "                data_save_class_sorted['f_name_'+classes[c]] = f_name_arrays\n",
    "                select_imgs =  int(len(f_name_arrays) * (self.args.p/19))\n",
    "\n",
    "                selct = f_name_arrays[0:select_imgs]\n",
    "                f_ev.write(classes[c]+'\\n')\n",
    "                for loop in f_name_arrays[0:10]:\n",
    "                    f_ev.write(loop+'\\n')\n",
    "                \n",
    "                    \n",
    "                \n",
    "\n",
    "                ######Dynamic threshold of each class##############\n",
    "\n",
    "                f_n = f_name_arrays[select_imgs]\n",
    "                img= load_single_image(f_n)\n",
    "                img = img.reshape(1,3,IMG_H,IMG_W)\n",
    "                img = torch.from_numpy(img).float().to(device)\n",
    "                out_ = self.model(Variable(img).cuda())\n",
    "                out_ = nn.functional.softmax(out_, dim=1)\n",
    "                out_=out_.cpu().data[0].numpy()\n",
    "                y_pred = keras_out(out_)\n",
    "\n",
    "\n",
    "                Y_argmax = np.argmax(y_pred,axis = -1)[0]\n",
    "                SE_main = self_entropy(y_pred)\n",
    "\n",
    "                if(self.args.entropy_normalization):\n",
    "                    SE_main = ent_normalization(SE_main,y_pred)\n",
    "\n",
    "                class_se = SE_main[Y_argmax == c]\n",
    "                mean_class_se = np.mean(class_se) * self.args.ent_th_on_class_gain\n",
    "\n",
    "\n",
    "                self.entropy_th_class[0][c] = mean_class_se\n",
    "\n",
    "                ##############################################\n",
    "\n",
    "                over_all_list += selct\n",
    "            \n",
    "        over_all_list = list(dict.fromkeys(over_all_list))\n",
    "        for loop in over_all_list:\n",
    "            f.write(loop+'\\n')\n",
    "            self.cnt_img +=1\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def global_sort(self):\n",
    "        self.args.data_label_folder_target = None \n",
    "        self.args.shuffel_ = False\n",
    "        self.args.data_dir_target = root_base +'/dataset/cityscapes'\n",
    "        self.args.data_list_target = root_base +'/dataset/cityscapes_list/train.txt'\n",
    "        self.args.num_steps = self.args.total_no_of_target\n",
    "        self.args.batch_size = 1\n",
    "        self.model.eval()\n",
    "        self.model.cuda()    \n",
    "        targetloader = CreateTrgDataLoader(self.args)\n",
    "        data_save_global = {\"f_name\":[],\"max_prob_values\":[]} \n",
    "        \n",
    "        for index, batch in tqdm.tqdm(enumerate(targetloader)):\n",
    "            \n",
    "            image, _, name ,__= batch\n",
    "            fn = name[0]\n",
    "#             print(fn)\n",
    "            output = self.model(Variable(image).cuda())\n",
    "            output = nn.functional.softmax(output, dim=1)\n",
    "            output=output.cpu().data[0].numpy()\n",
    "            y_pred = keras_out(output)\n",
    "\n",
    "            MP_max = np.max(y_pred,axis = -1)[0]\n",
    "          \n",
    "            data_save_global['f_name'].append(fn)\n",
    "            data_save_global['max_prob_values'].append(np.mean(MP_max))\n",
    "\n",
    "        max_prob_sorted_ascending, f_name_arrays = zip(*sorted(zip(data_save_global['max_prob_values'], data_save_global['f_name'])))\n",
    "        f_name_arrays = f_name_arrays[::-1]\n",
    "        max_prob_sorted_ascending = max_prob_sorted_ascending[::-1]\n",
    "\n",
    "        data_save_global['f_name'] = f_name_arrays\n",
    "        data_save_global['max_prob_values'] = max_prob_sorted_ascending\n",
    "        \n",
    "        f = open(sorted_list,\"w+\")\n",
    "        for loop in data_save_global['f_name']:\n",
    "            f.write(loop+'\\n')\n",
    "            \n",
    "        \n",
    "          \n",
    "    \n",
    "    def save_data(self,patch_x, patch_y, path,i,map_):\n",
    "      \n",
    "        Y = np.argmax(patch_y,axis = -1)\n",
    "        if(map_ != 'a'):\n",
    "            Y[map_ == 0] = 255\n",
    "        plt.imsave( path +\"images/\"+ str(i)+'.png',patch_x)  #p_small_data\n",
    "        Y=np.asarray(Y,dtype=np.uint8)\n",
    "        \n",
    "       \n",
    "        Y=Image.fromarray(Y,mode = 'L')\n",
    "\n",
    "        \n",
    "        Y.save(path+ \"labels/\"+str(i)+'.png')\n",
    "        \n",
    "    def Data_Generate(self):\n",
    "        if(self.args.patch_select_method == 'smart'):\n",
    "            self.data_generate_smart()\n",
    "        else:\n",
    "            self.data_generator()\n",
    "            \n",
    "    def data_generate_smart(self):\n",
    "        self.args.data_label_folder_target = None\n",
    "        if(self.args.sorting_method == 'class_wise'):\n",
    "            stop_point = self.cnt_img\n",
    "        else:\n",
    "            stop_point = int(self.args.p * self.args.total_no_of_target)\n",
    "            \n",
    "       \n",
    "        self.args.shuffel_ = False\n",
    "        self.args.data_dir_target = root_base +'/dataset/cityscapes'\n",
    "        self.args.data_list_target = sorted_list\n",
    "        \n",
    "        self.args.batch_size = 1\n",
    "        self.model.eval()\n",
    "        self.model.cuda()    \n",
    "        targetloader = CreateTrgDataLoader(self.args)\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        f = open(data_gen_list,\"w+\")\n",
    "        print(\"***********Generating Data smart***********\")\n",
    "        print(\"Total it : \",stop_point+1)\n",
    "        for index, batch in tqdm.tqdm(enumerate(targetloader)):\n",
    "            \n",
    "            if(index > stop_point):\n",
    "                break\n",
    "            \n",
    "            image, _, name, rl_img = batch\n",
    "            fn = name[0]\n",
    "            output = self.model(Variable(image).cuda())\n",
    "            output = nn.functional.softmax(output, dim=1)\n",
    "            rl_img = rl_img.cpu().data[0].numpy()/255.0\n",
    "            output=output.cpu().data[0].numpy()\n",
    "            \n",
    "            image=image.cpu().data[0].numpy()\n",
    "            image = np.rollaxis(image, axis = -1)\n",
    "            image = np.rollaxis(image, axis = -1)\n",
    "            \n",
    "            if(self.args.balance_on_priors):\n",
    "                wei = (1 - weight_mat )\n",
    "                output = np.multiply(output,wei)\n",
    "                    \n",
    "            \n",
    "            \n",
    "            Y_pred = keras_out(output)\n",
    "            \n",
    "            ################################################\n",
    "            map_ = np.zeros((IMG_H,IMG_W))\n",
    "            SE = self_entropy(Y_pred)\n",
    "            \n",
    "            if(self.args.entropy_normalization):\n",
    "                SE = ent_normalization(SE,Y_pred)\n",
    "            \n",
    "            if(self.args.ent_th_on_class):\n",
    "                \n",
    "                for il in range(IMG_H):\n",
    "                    for ij in range(IMG_W):\n",
    "                        if(SE[il][ij] >= self.entropy_th_class[0][np.argmax(Y_pred[0][il][ij],axis = -1)]):\n",
    "                            map_[il][ij] =  0\n",
    "                        else:\n",
    "                            map_[il][ij] =  1\n",
    "                                    \n",
    "            else:\n",
    "            \n",
    "                map_[SE >= self.args.entropy_th] =  0\n",
    "                map_[SE < self.args.entropy_th] =  1\n",
    "            cnt_flag = 0\n",
    "            \n",
    "            ###################save orignal#################\n",
    "            \n",
    "#             f.write(str(count)+\".png\"+'\\n')\n",
    "#             self.save_data(rl_img, Y_pred.reshape(IMG_H,IMG_W,19), generated_data,(count),'a')\n",
    "#             count +=1\n",
    "            ##########################################\n",
    "            \n",
    "            \n",
    "            for patch in range(self.args.total_patches_in_smart):\n",
    "\n",
    "                point_X_s = self.args.patch_size[1]\n",
    "                point_Y_s = self.args.patch_size[0]\n",
    "\n",
    "                \n",
    "                point_X = random.randint(0, IMG_W-point_X_s)\n",
    "                point_Y = random.randint(0, IMG_H - point_Y_s)\n",
    "                \n",
    "                #########################################\n",
    "                x_mean_patch =  image[ point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(point_Y_s,point_X_s,3)\n",
    "                map_patch = map_[point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(point_Y_s,point_X_s)\n",
    "   \n",
    "                x_PATCH =  rl_img[ point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(point_Y_s,point_X_s,3)\n",
    "                y_PATCH =  Y_pred[0, point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(1,point_Y_s,point_X_s,19)\n",
    "                \n",
    "            \n",
    "                y_PATCH = np.rollaxis(y_PATCH[0], axis = -1).reshape(1,19,point_Y_s,point_X_s)\n",
    "                y_PATCH = torch.from_numpy(y_PATCH).float().to(device)\n",
    "                Y_Patch_resize = nn.functional.upsample(y_PATCH, (IMG_H, IMG_W), mode='bilinear', align_corners=True).cpu().data[0].numpy()\n",
    "                Y_Patch_resize = np.rollaxis(Y_Patch_resize, axis = -1)\n",
    "                Y_Patch_resize = np.rollaxis(Y_Patch_resize, axis = -1).reshape(1,IMG_H,IMG_W,19)\n",
    "\n",
    "            \n",
    "            \n",
    "                \n",
    "                #############smart patch seperateeeeeer#########\n",
    "                x_mean_patch = np.rollaxis(x_mean_patch, axis = -1).reshape(1,3,point_Y_s,point_X_s)\n",
    "                x_mean_patch = torch.from_numpy(x_mean_patch).float().to(device)\n",
    "                x_mean_res = nn.functional.upsample(x_mean_patch, (IMG_H, IMG_W), mode='bilinear', align_corners=True)\n",
    "                \n",
    "                \n",
    "                output = self.model(Variable(x_mean_res).cuda())\n",
    "                output = nn.functional.softmax(output, dim=1)\n",
    "                output=output.cpu().data[0].numpy()\n",
    "                y_patch_out = keras_out(output)\n",
    "                \n",
    "                SE_main = self_entropy(Y_Patch_resize)\n",
    "                SE_patch = self_entropy(y_patch_out)\n",
    "                \n",
    "                diff = (np.mean(SE_patch) - np.mean(SE_main))\n",
    "                \n",
    "                ##################################\n",
    "                \n",
    "                if(diff >= self.args.entropy_diff_th):\n",
    "                    #####################code new ################\n",
    "                    x_PATCH = np.rollaxis(x_PATCH, axis = -1).reshape(1,3,point_Y_s,point_X_s)\n",
    "                    x_PATCH = torch.from_numpy(x_PATCH).float().to(device)\n",
    "\n",
    "                    \n",
    "                    map_patch = map_patch.reshape(1,1,point_Y_s,point_X_s)\n",
    "                    map_patch = torch.from_numpy(map_patch).float().to(device)\n",
    "\n",
    "                    X_Patch_resize = nn.functional.upsample(x_PATCH, (IMG_H, IMG_W), mode='bilinear', align_corners=True).cpu().data[0].numpy()\n",
    "                    X_Patch_resize = np.rollaxis(X_Patch_resize, axis = -1)\n",
    "                    X_Patch_resize = np.rollaxis(X_Patch_resize, axis = -1)\n",
    "\n",
    "\n",
    "                    Y_Patch_resize = nn.functional.upsample(y_PATCH, (IMG_H, IMG_W), mode='bilinear', align_corners=True).cpu().data[0].numpy()\n",
    "                    Y_Patch_resize = np.rollaxis(Y_Patch_resize, axis = -1)\n",
    "                    Y_Patch_resize = np.rollaxis(Y_Patch_resize, axis = -1).reshape(1,IMG_H,IMG_W,19)\n",
    "\n",
    "\n",
    "                    map_patch_re = nn.functional.upsample(map_patch, (IMG_H, IMG_W), mode='bilinear', align_corners=True).cpu().data[0].numpy()\n",
    "                    map_patch_re = map_patch_re[0]\n",
    "\n",
    "                    #############################################\n",
    "                    cnt_flag +=1\n",
    "                    f.write(str(count+cnt_flag)+\".png\"+'\\n')\n",
    "                    self.save_data(X_Patch_resize, Y_Patch_resize.reshape(IMG_H,IMG_W,19), generated_data,(count+cnt_flag),map_patch_re)\n",
    "                    \n",
    "                \n",
    "                \n",
    "                if(cnt_flag >= self.args.no_of_patches_per_image):\n",
    "                    break\n",
    "            count+=self.args.no_of_patches_per_image + 1\n",
    "            \n",
    "        print(\"*****************END****************\")\n",
    "        \n",
    "        \n",
    "    def data_generator(self):\n",
    "        self.args.data_label_folder_target = None\n",
    "        if(self.args.sorting_method == 'class_wise'):\n",
    "            stop_point = self.cnt_img\n",
    "        else:\n",
    "            stop_point = int(self.args.p * self.args.total_no_of_target)\n",
    "            \n",
    "       \n",
    "        self.args.shuffel_ = False\n",
    "        self.args.data_dir_target = root_base +'/dataset/cityscapes'\n",
    "        self.args.data_list_target = sorted_list\n",
    "        \n",
    "        self.args.batch_size = 1\n",
    "        self.model.eval()\n",
    "        self.model.cuda()    \n",
    "        targetloader = CreateTrgDataLoader(self.args)\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        f = open(data_gen_list,\"w+\")\n",
    "        print(\"***********Generating Data Random***********\")\n",
    "        print(\"Total it : \",stop_point+1)\n",
    "        for index, batch in tqdm.tqdm(enumerate(targetloader)):\n",
    "            \n",
    "            if(index > stop_point):\n",
    "                break\n",
    "            \n",
    "            image, _, name, rl_img = batch\n",
    "            fn = name[0]\n",
    "            output = self.model(Variable(image).cuda())\n",
    "            output = nn.functional.softmax(output, dim=1)\n",
    "            rl_img = rl_img.cpu().data[0].numpy()/255.0\n",
    "            output=output.cpu().data[0].numpy()\n",
    "             \n",
    "            \n",
    "            if(self.args.balance_on_priors):\n",
    "                wei = (1 - weight_mat )\n",
    "                output = np.multiply(output,wei)\n",
    "                    \n",
    "            \n",
    "            \n",
    "            Y_pred = keras_out(output)\n",
    "            \n",
    "            ###############################################\n",
    "            map_ = np.zeros((IMG_H,IMG_W))\n",
    "            SE = self_entropy(Y_pred)\n",
    "            \n",
    "            if(self.args.entropy_normalization):\n",
    "                SE = ent_normalization(SE,Y_pred)\n",
    "            \n",
    "            if(self.args.ent_th_on_class):\n",
    "                \n",
    "                for il in range(IMG_H):\n",
    "                    for ij in range(IMG_W):\n",
    "                        \n",
    "                        if(SE[il][ij] >= self.entropy_th_class[0][np.argmax(Y_pred[0][il][ij],axis = -1)]):\n",
    "                            map_[il][ij] =  0\n",
    "                        else:\n",
    "                            map_[il][ij] =  1\n",
    "                                    \n",
    "            else:\n",
    "            \n",
    "                map_[SE >= self.args.entropy_th] =  0\n",
    "                map_[SE < self.args.entropy_th] =  1\n",
    "            ###################save orignal#################\n",
    "            \n",
    "#             f.write(str(count)+\".png\"+'\\n')\n",
    "#             self.save_data(rl_img, Y_pred.reshape(IMG_H,IMG_W,19), generated_data,(count),map_)\n",
    "#             count +=1\n",
    "            ##########################################\n",
    "            \n",
    "            if(self.args.shrink_image):\n",
    "                f.write(str(count)+\".png\"+'\\n')\n",
    "                IMG_SS = np.zeros((IMG_H,IMG_W,3))\n",
    "                Y_PRE_SS = np.zeros((1,IMG_H,IMG_W,19))\n",
    "                MAP_SS= np.zeros((IMG_H,IMG_W))\n",
    "                \n",
    "                img_ss = resize(rl_img, (self.args.patch_size[0], self.args.patch_size[1]), anti_aliasing=True)\n",
    "                y_pred_ss = resize(Y_pred, (1,self.args.patch_size[0], self.args.patch_size[1]), anti_aliasing=False)\n",
    "                \n",
    "                point_X_s = self.args.patch_size[1]\n",
    "                point_Y_s = self.args.patch_size[0]\n",
    "\n",
    "\n",
    "#                 point_X = random.randint(0, IMG_W-point_X_s)\n",
    "#                 point_Y = random.randint(0, IMG_H - point_Y_s)\n",
    "                \n",
    "                point_X = 256\n",
    "                point_Y = 128\n",
    "                \n",
    "\n",
    "                IMG_SS[point_Y:point_Y+self.args.patch_size[0] , point_X:point_X+self.args.patch_size[1]]= img_ss\n",
    "                Y_PRE_SS[0,point_Y:point_Y+self.args.patch_size[0] , point_X:point_X+self.args.patch_size[1]]= y_pred_ss\n",
    "                MAP_SS[point_Y:point_Y+self.args.patch_size[0] , point_X:point_X+self.args.patch_size[1]] =1\n",
    "                \n",
    "                self.save_data(IMG_SS, Y_PRE_SS.reshape(IMG_H,IMG_W,19), generated_data,(count),MAP_SS)\n",
    "                count +=1\n",
    "                \n",
    "            for patch in range(self.args.no_of_patches_per_image):\n",
    "                \n",
    "#                 point_X_s = 256 * (patch +1)\n",
    "#                 point_Y_s = int(point_X_s/2)\n",
    "                \n",
    "#                 point_X = 512 - int(point_X_s/2)\n",
    "#                 point_Y = 256 - int(point_Y_s/2)\n",
    "                \n",
    "                if(self.args.patch_size[1] == 1024):\n",
    "                    X_Patch_resize = rl_img\n",
    "                    Y_Patch_resize = Y_pred\n",
    "                    map_patch_re = map_\n",
    "                    \n",
    "                else:\n",
    "\n",
    "                    point_X_s = self.args.patch_size[1]\n",
    "                    point_Y_s = self.args.patch_size[0]\n",
    "\n",
    "\n",
    "                    point_X = random.randint(0, IMG_W-point_X_s)\n",
    "                    point_Y = random.randint(0, IMG_H - point_Y_s)\n",
    "\n",
    "\n",
    "\n",
    "                    x_PATCH =  rl_img[ point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(point_Y_s,point_X_s,3)\n",
    "                    y_PATCH =  Y_pred[0, point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(1,point_Y_s,point_X_s,19)\n",
    "                    map_patch = map_[point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(point_Y_s,point_X_s)\n",
    "                    \n",
    "                    \n",
    "                    ################resize on pytorch ###############\n",
    "                    x_PATCH = np.rollaxis(x_PATCH, axis = -1).reshape(1,3,point_Y_s,point_X_s)\n",
    "                    x_PATCH = torch.from_numpy(x_PATCH).float().to(device)\n",
    "                    \n",
    "                    y_PATCH = np.rollaxis(y_PATCH[0], axis = -1).reshape(1,19,point_Y_s,point_X_s)\n",
    "                    y_PATCH = torch.from_numpy(y_PATCH).float().to(device)\n",
    "                    \n",
    "                    map_patch = map_patch.reshape(1,1,point_Y_s,point_X_s)\n",
    "                    map_patch = torch.from_numpy(map_patch).float().to(device)\n",
    "                    \n",
    "                    X_Patch_resize = nn.functional.upsample(x_PATCH, (IMG_H, IMG_W), mode='bilinear', align_corners=True).cpu().data[0].numpy()\n",
    "                    X_Patch_resize = np.rollaxis(X_Patch_resize, axis = -1)\n",
    "                    X_Patch_resize = np.rollaxis(X_Patch_resize, axis = -1)\n",
    "                    \n",
    "                    \n",
    "                    Y_Patch_resize = nn.functional.upsample(y_PATCH, (IMG_H, IMG_W), mode='bilinear', align_corners=True).cpu().data[0].numpy()\n",
    "                    Y_Patch_resize = np.rollaxis(Y_Patch_resize, axis = -1)\n",
    "                    Y_Patch_resize = np.rollaxis(Y_Patch_resize, axis = -1).reshape(1,IMG_H,IMG_W,19)\n",
    "                    \n",
    "                    \n",
    "                    map_patch_re = nn.functional.upsample(map_patch, (IMG_H, IMG_W), mode='bilinear', align_corners=True).cpu().data[0].numpy()\n",
    "                    map_patch_re = map_patch_re[0]\n",
    "                   \n",
    "                    #####################################\n",
    "                    \n",
    "                    \n",
    "#                     X_Patch_resize = resize(x_PATCH, (IMG_H, IMG_W), anti_aliasing=False)\n",
    "#                     Y_Patch_resize = resize(y_PATCH, (1,IMG_H, IMG_W), anti_aliasing=False)\n",
    "#                     map_patch_re = resize(map_patch, (IMG_H, IMG_W), anti_aliasing=False)\n",
    "                \n",
    "\n",
    "\n",
    "                f.write(str(count+patch)+\".png\"+'\\n')\n",
    "                self.save_data(X_Patch_resize, Y_Patch_resize.reshape(IMG_H,IMG_W,19), generated_data,(count+patch),map_patch_re)\n",
    "                \n",
    "                \n",
    "            count+=self.args.no_of_patches_per_image + 1\n",
    "        print(\"*****************END****************\")\n",
    "            \n",
    "             \n",
    "    \n",
    "                \n",
    "    def gaussian(self, ins,mean, stddev):\n",
    "  \n",
    "        noise = Variable(ins.data.new(ins.size()).normal_(mean,stddev))\n",
    "        \n",
    "        return ins + noise\n",
    "            \n",
    "    def train_adp(self,round_):\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.args.data_label_folder_target = root_base +'/dataset/generated_data/'   \n",
    "        self.args.shuffel_ = True\n",
    "        self.args.data_dir_target = root_base +'/dataset/generated_data/'\n",
    "        self.args.data_list_target = data_gen_list\n",
    "        self.args.batch_size = 1\n",
    "        \n",
    "        _t = {'iter time' : Timer()}\n",
    "       \n",
    "        if(self.args.sorting_method == 'class_wise'):\n",
    "            self.args.num_steps = int(self.cnt_img * self.args.epoch_per_round * self.args.no_of_patches_per_image)\n",
    "        else:\n",
    "            \n",
    "            self.args.num_steps = int(self.args.p*self.args.total_no_of_target*self.args.no_of_patches_per_image *self.args.epoch_per_round)\n",
    "     \n",
    "            \n",
    "           \n",
    "        sourceloader, targetloader = CreateSrcDataLoader(self.args), CreateTrgDataLoader(self.args)\n",
    "        targetloader_iter, sourceloader_iter = iter(targetloader), iter(sourceloader)\n",
    "        \n",
    "        \n",
    "        start_iter = 0\n",
    "#         if self.args.restore_from is not None:\n",
    "#             start_iter = int(self.args.restore_from.rsplit('/', 1)[1].rsplit('_')[1])\n",
    "        \n",
    "#         train_writer = tensorboardX.SummaryWriter(os.path.join(self.args.snapshot_dir, \"logs\", model_name))\n",
    "    \n",
    "#         bce_loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        cudnn.enabled = True\n",
    "        cudnn.benchmark = True\n",
    "        self.model.train()\n",
    "        self.model.cuda()\n",
    "\n",
    "        loss = ['loss_seg_src', 'loss_seg_trg']\n",
    "        _t['iter time'].tic()\n",
    "        for i in range(start_iter, self.args.num_steps):\n",
    "            \n",
    "            self.model.adjust_learning_rate(self.args, self.optimizer, i)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            src_img, src_lbl, _, _ = sourceloader_iter.next()\n",
    "            \n",
    "            src_img, src_lbl = Variable(src_img).cuda(), Variable(src_lbl.long()).cuda()\n",
    "            src_seg_score = self.model(src_img, lbl=src_lbl)       \n",
    "            loss_seg_src = self.model.loss\n",
    "    \n",
    "            loss_src = torch.mean(loss_seg_src)     \n",
    "            ##############################\n",
    "            loss_src.backward()\n",
    "            \n",
    "            \n",
    "            \n",
    "           \n",
    "           \n",
    "            \n",
    "            trg_img, trg_lbl, _, _ = targetloader_iter.next()\n",
    "            trg_img, trg_lbl = Variable(trg_img).cuda(), Variable(trg_lbl.long()).cuda()\n",
    "#             trg_img = self.gaussian(trg_img,0, 0.02)\n",
    "            trg_seg_score = self.model(trg_img, lbl=trg_lbl) \n",
    " \n",
    "            ############################\n",
    "            loss_seg_trg = self.model.loss \n",
    "            \n",
    "            ##########Focal loss############\n",
    "            loss_trg_2 = torch.mean(loss_seg_trg)\n",
    "            if(self.args.focal_flag):\n",
    "                    #try to minimize segmentation loss\n",
    "\n",
    "\n",
    "                pt = torch.exp(-loss_seg_trg)\n",
    "                loss_trg =   loss_seg_trg  * (1-pt)**self.args.gamma\n",
    "                trg_fcl = torch.mean(loss_trg)\n",
    "            else:\n",
    "                trg_fcl =0\n",
    "            \n",
    "            loss_trg =  0.1 *trg_fcl  + loss_trg_2\n",
    "            \n",
    "            \n",
    "            ##############################\n",
    "#             over_all_loss =   loss_trg     \n",
    "  \n",
    "            loss_trg.backward()\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            src_seg_score, trg_seg_score = src_seg_score.detach(), trg_seg_score.detach()\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "#             for m in loss:\n",
    "#                 train_writer.add_scalar(m, eval(m), i+1)\n",
    "\n",
    "            if (i+1) % 500 == 0:\n",
    "                print ('taking snapshot ...')\n",
    "                torch.save(self.model.state_dict(), os.path.join(self.args.snapshot_dir, '%s_' %(self.args.source+\"_to_\" +self.args.target )+\"_\"+ self.args.Expriment_name +str(round_) +'.pth' ))   \n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                _t['iter time'].toc(average=False)\n",
    "                print ('[it %d][src seg loss %.4f][lr %.4f][%.2fs]' % \\\n",
    "                        (i + 1, loss_src.data, self.optimizer.param_groups[0]['lr']*10000, _t['iter time'].diff))\n",
    "                if i + 1 > self.args.num_steps_stop:\n",
    "                    print ('finish training')\n",
    "                    break\n",
    "                _t['iter time'].tic()\n",
    "\n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mGjOa-s6QqIe"
   },
   "source": [
    "\n",
    "\n",
    "load init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VgQm8tD6QqIf"
   },
   "outputs": [],
   "source": [
    "model_initl = model_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iNjv7BshQqIq"
   },
   "source": [
    "Experiment's Settigns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60jAkqx8QqIr"
   },
   "outputs": [],
   "source": [
    "model_initl.args.focal_flag = True\n",
    "model_initl.args.shrink_image = False\n",
    "\n",
    "model_initl.args.Expriment_name = 'Exp_Final_syntia_with_focal'     # name of an experiment\n",
    "model_initl.args.p =0.1                # p is the portion for selecion of samples in target data ==> p*Total number of images\n",
    "model_initl.args.no_of_patches_per_image = 4 # number of patchs extarct from each image\n",
    "model_initl.args.gamma = 3                 # (1-prediction)**gamma  ==> focal loss\n",
    "model_initl.args.learning_rate = 1e-12 # learning rate\n",
    "# model_initl.args.entropy_th = 1.3            # Entropy map's threshold \n",
    "Rounds = int(1/model_initl.args.p)           # Total number of rounds \n",
    "model_initl.args.epoch_per_round = 2   # epoch each round\n",
    "\n",
    "model_initl.args.sorting_method = 'class_wise'   # 'global' or 'class_wise'\n",
    "model_initl.args.total_no_of_target = 2975         # Total number of target images\n",
    "\n",
    "\n",
    "model_initl.args.patch_select_method = 'random'           # 'smart'  or 'random'\n",
    "model_initl.args.total_patches_in_smart=None     # toatal number of patches in smart selection\n",
    "model_initl.args.entropy_diff_th = None            # we select the specific patch which have entropy diff greater than this threshold\n",
    "                                                          # seleection range  0.1  to 0.6\n",
    "\n",
    "model_initl.args.balance_on_priors = False          # balance the prediction with priors info of area pred*(1-area)\n",
    "model_initl.args.entropy_normalization = True      # entropy normalization or not\n",
    "model_initl.args.patch_size = (256,512)\n",
    "\n",
    "model_initl.args.ent_th_on_class = True        #Apply unique entropy threshold of each class seperately\n",
    "model_initl.args.ent_th_on_class_gain = 1    # gain on class based entropy threshold \n",
    "\n",
    "\n",
    "print_args(model_initl.args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1759,
     "status": "ok",
     "timestamp": 1581505357557,
     "user": {
      "displayName": "Muhammad Naseer Subhani",
      "photoUrl": "",
      "userId": "06699857406068047110"
     },
     "user_tz": -300
    },
    "id": "-TwG53R2QqIt",
    "outputId": "626afd3c-8a8c-4416-e569-5358203dcc87",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "           Expriment_name: Exp_Final_syntia_with_focal   \n",
      "        balance_on_priors: False                         \n",
      "               batch_size: 1                             \n",
      "                 data_dir: /home/olektra_gpu/Desktop/olektra projects/ECCV/dataset/synthia\n",
      "          data_dir_target: /home/olektra_gpu/Desktop/olektra projects/ECCV/dataset/cityscapes\n",
      " data_label_folder_target: None                          \n",
      "                data_list: /home/olektra_gpu/Desktop/olektra projects/ECCV/dataset/synthia_list/train.txt\n",
      "         data_list_target: /home/olektra_gpu/Desktop/olektra projects/ECCV/dataset/cityscapes_list/train.txt\n",
      "          ent_th_on_class: True                          \n",
      "     ent_th_on_class_gain: 1                             \n",
      "          entropy_diff_th: None                          \n",
      "    entropy_normalization: True                          \n",
      "          epoch_per_round: 2                             \n",
      "               focal_flag: True                          \n",
      "                    gamma: 3                             \n",
      "             init_weights: None                          \n",
      "        lambda_adv_target: 0.001                         \n",
      "            learning_rate: 1e-12                         \n",
      "          learning_rate_D: 0.0001                        \n",
      "                    model: DeepLab                       \n",
      "                 momentum: 0.9                           \n",
      "  no_of_patches_per_image: 4                             \n",
      "              num_classes: 19                            \n",
      "                num_steps: 250000                        \n",
      "           num_steps_stop: 120000                        \n",
      "              num_workers: 2                             \n",
      "                        p: 0.1                           \n",
      "      patch_select_method: random                        \n",
      "               patch_size: (256, 512)                    \n",
      "                    power: 0.9                           \n",
      "               print_freq: 100                           \n",
      "             restore_from: /home/olektra_gpu/Desktop/olektra projects/ECCV/init_models/init/syn_2_city_deeplab\n",
      "          save_pred_every: 10000                         \n",
      "                      set: train                         \n",
      "             shrink_image: False                         \n",
      "                 shuffel_: False                         \n",
      "             snapshot_dir: /home/olektra_gpu/Desktop/olektra projects/ECCV/snapshots/\n",
      "           sorting_method: class_wise                    \n",
      "                   source: synthia                       \n",
      "                   target: cityscapes                    \n",
      "       total_no_of_target: 2975                          \n",
      "   total_patches_in_smart: None                          \n",
      "             weight_decay: 0.0005                        \n",
      "----------------- End -------------------\n"
     ]
    }
   ],
   "source": [
    "model_initl.opt.print_options(model_initl.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sB9sKyEaQqIx"
   },
   "outputs": [],
   "source": [
    "Base = Base_Adaptation(model_initl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 939416,
     "status": "error",
     "timestamp": 1581506949625,
     "user": {
      "displayName": "Muhammad Naseer Subhani",
      "photoUrl": "",
      "userId": "06699857406068047110"
     },
     "user_tz": -300
    },
    "id": "TE4Vcf-MQqI0",
    "outputId": "9e23211f-af13-46b2-da65-5edae2535e1a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Round  0  #####################\n",
      "*********** Finding most confident samples using class_wise  ***********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/olektra_gpu/.local/lib/python3.5/site-packages/torch/nn/functional.py:2416: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "2975it [33:59,  1.46it/s]\n",
      "/home/olektra_gpu/.local/lib/python3.5/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************END********************\n",
      "***********Generating Data Random***********\n",
      "Total it :  165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/olektra_gpu/.local/lib/python3.5/site-packages/ipykernel_launcher.py:208: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "165it [15:58,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************END****************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olektra_gpu/.local/lib/python3.5/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[it 100][src seg loss 0.1732][lr 0.0000][575.03s]\n",
      "[it 200][src seg loss 0.1089][lr 0.0000][557.56s]\n",
      "[it 300][src seg loss 0.0811][lr 0.0000][557.77s]\n",
      "[it 400][src seg loss 0.0839][lr 0.0000][557.31s]\n",
      "taking snapshot ...\n",
      "[it 500][src seg loss 0.0638][lr 0.0000][557.96s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f7a774ad8204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData_Generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_adp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtesting_entr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmIoU_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_time_evaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrecord_entropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_entr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-6bc546095790>\u001b[0m in \u001b[0;36mtrain_adp\u001b[0;34m(self, round_)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0mtrg_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_lbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargetloader_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m             \u001b[0mtrg_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_lbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_lbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;31m#             trg_img = self.gaussian(trg_img,0, 0.02)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0mtrg_seg_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrg_lbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Base.args.p = 0.1\n",
    "first_di = 0\n",
    "record_entropy = []\n",
    "record_mIoU_ = []\n",
    "prev_entropy = 12345666555433232234234\n",
    "for round_ in range(Rounds):\n",
    "    print(\"############### Round \",round_,\" #####################\")\n",
    "    Base.sorting()\n",
    "    Base.Data_Generate()\n",
    "    Base.train_adp(round_)\n",
    "    testing_entr, mIoU_ = run_time_evaluation.main(Base.model)\n",
    "    record_entropy.append(np.mean(testing_entr))\n",
    "    record_mIoU_.append(mIoU_)\n",
    "    Base.args.p = Base.args.p+0.05\n",
    "    print(\"#################### Round END #######################\")\n",
    "    diff = prev_entropy - np.mean(testing_entr)\n",
    "\n",
    "    if(diff < 0):\n",
    "        break\n",
    "#     if( diff  <  1 and round_ > 0):\n",
    "#         break\n",
    "#     if(round_ == 1):\n",
    "#         first_di = diff\n",
    "#     if(first_di != 0 and diff > 0):\n",
    "#         Base.args.learning_rate = Base.args.learning_rate * (diff/first_di)\n",
    "    if(Base.args.p > 0.5):\n",
    "        break\n",
    "    clear_output()\n",
    "    prev_entropy = np.mean(testing_entr)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.13s/it]\u001b[A\n",
      "2it [00:02,  1.13s/it]\u001b[A\n",
      "3it [00:03,  1.13s/it]\u001b[A\n",
      "4it [00:04,  1.13s/it]\u001b[A\n",
      "5it [00:05,  1.13s/it]\u001b[A\n",
      "6it [00:06,  1.13s/it]\u001b[A\n",
      "7it [00:07,  1.12s/it]\u001b[A\n",
      "8it [00:09,  1.12s/it]\u001b[A\n",
      "9it [00:10,  1.13s/it]\u001b[A\n",
      "10it [00:11,  1.13s/it]\u001b[A\n",
      "11it [00:12,  1.12s/it]\u001b[A\n",
      "12it [00:13,  1.12s/it]\u001b[A\n",
      "13it [00:14,  1.12s/it]\u001b[A\n",
      "14it [00:15,  1.12s/it]\u001b[A\n",
      "15it [00:16,  1.12s/it]\u001b[A\n",
      "16it [00:17,  1.12s/it]\u001b[A\n",
      "17it [00:19,  1.12s/it]\u001b[A\n",
      "18it [00:20,  1.12s/it]\u001b[A\n",
      "19it [00:21,  1.12s/it]\u001b[A\n",
      "20it [00:22,  1.12s/it]\u001b[A\n",
      "21it [00:23,  1.12s/it]\u001b[A\n",
      "22it [00:24,  1.12s/it]\u001b[A\n",
      "23it [00:25,  1.12s/it]\u001b[A\n",
      "24it [00:26,  1.12s/it]\u001b[A\n",
      "25it [00:28,  1.12s/it]\u001b[A\n",
      "26it [00:29,  1.13s/it]\u001b[A\n",
      "27it [00:30,  1.13s/it]\u001b[A\n",
      "28it [00:31,  1.12s/it]\u001b[A\n",
      "29it [00:32,  1.12s/it]\u001b[A\n",
      "30it [00:33,  1.12s/it]\u001b[A\n",
      "31it [00:34,  1.12s/it]\u001b[A\n",
      "32it [00:35,  1.12s/it]\u001b[A\n",
      "33it [00:37,  1.12s/it]\u001b[A\n",
      "34it [00:38,  1.12s/it]\u001b[A\n",
      "35it [00:39,  1.12s/it]\u001b[A\n",
      "36it [00:40,  1.12s/it]\u001b[A\n",
      "37it [00:41,  1.12s/it]\u001b[A\n",
      "38it [00:42,  1.12s/it]\u001b[A\n",
      "39it [00:43,  1.12s/it]\u001b[A\n",
      "40it [00:44,  1.12s/it]\u001b[A\n",
      "41it [00:45,  1.12s/it]\u001b[A\n",
      "42it [00:47,  1.12s/it]\u001b[A\n",
      "43it [00:48,  1.12s/it]\u001b[A\n",
      "44it [00:49,  1.12s/it]\u001b[A\n",
      "45it [00:50,  1.12s/it]\u001b[A\n",
      "46it [00:51,  1.12s/it]\u001b[A\n",
      "47it [00:52,  1.13s/it]\u001b[A\n",
      "48it [00:53,  1.12s/it]\u001b[A\n",
      "49it [00:54,  1.12s/it]\u001b[A\n",
      "50it [00:56,  1.12s/it]\u001b[A\n",
      "51it [00:57,  1.12s/it]\u001b[A\n",
      "52it [00:58,  1.12s/it]\u001b[A\n",
      "53it [00:59,  1.12s/it]\u001b[A\n",
      "54it [01:00,  1.12s/it]\u001b[A\n",
      "55it [01:01,  1.12s/it]\u001b[A\n",
      "56it [01:02,  1.12s/it]\u001b[A\n",
      "57it [01:03,  1.13s/it]\u001b[A\n",
      "58it [01:05,  1.12s/it]\u001b[A\n",
      "59it [01:06,  1.12s/it]\u001b[A\n",
      "60it [01:07,  1.12s/it]\u001b[A\n",
      "61it [01:08,  1.12s/it]\u001b[A\n",
      "62it [01:09,  1.12s/it]\u001b[A\n",
      "63it [01:10,  1.12s/it]\u001b[A\n",
      "64it [01:11,  1.12s/it]\u001b[A\n",
      "65it [01:12,  1.12s/it]\u001b[A\n",
      "66it [01:14,  1.12s/it]\u001b[A\n",
      "67it [01:15,  1.12s/it]\u001b[A\n",
      "68it [01:16,  1.12s/it]\u001b[A\n",
      "69it [01:17,  1.12s/it]\u001b[A\n",
      "70it [01:18,  1.12s/it]\u001b[A\n",
      "71it [01:19,  1.12s/it]\u001b[A\n",
      "72it [01:20,  1.12s/it]\u001b[A\n",
      "73it [01:21,  1.12s/it]\u001b[A\n",
      "74it [01:22,  1.12s/it]\u001b[A\n",
      "75it [01:24,  1.12s/it]\u001b[A\n",
      "76it [01:25,  1.12s/it]\u001b[A\n",
      "77it [01:26,  1.12s/it]\u001b[A\n",
      "78it [01:27,  1.12s/it]\u001b[A\n",
      "79it [01:28,  1.12s/it]\u001b[A\n",
      "80it [01:29,  1.12s/it]\u001b[A\n",
      "81it [01:30,  1.12s/it]\u001b[A\n",
      "82it [01:31,  1.12s/it]\u001b[A\n",
      "83it [01:33,  1.12s/it]\u001b[A\n",
      "84it [01:34,  1.13s/it]\u001b[A\n",
      "85it [01:35,  1.13s/it]\u001b[A\n",
      "86it [01:36,  1.13s/it]\u001b[A\n",
      "87it [01:37,  1.13s/it]\u001b[A\n",
      "88it [01:38,  1.12s/it]\u001b[A\n",
      "89it [01:39,  1.13s/it]\u001b[A\n",
      "90it [01:40,  1.12s/it]\u001b[A\n",
      "91it [01:42,  1.12s/it]\u001b[A\n",
      "92it [01:43,  1.12s/it]\u001b[A\n",
      "93it [01:44,  1.12s/it]\u001b[A\n",
      "94it [01:45,  1.12s/it]\u001b[A\n",
      "95it [01:46,  1.12s/it]\u001b[A\n",
      "96it [01:47,  1.12s/it]\u001b[A\n",
      "97it [01:48,  1.12s/it]\u001b[A\n",
      "98it [01:49,  1.12s/it]\u001b[A\n",
      "99it [01:51,  1.12s/it]\u001b[A\n",
      "100it [01:52,  1.12s/it]\u001b[A\n",
      "101it [01:53,  1.12s/it]\u001b[A\n",
      "102it [01:54,  1.12s/it]\u001b[A\n",
      "103it [01:55,  1.12s/it]\u001b[A\n",
      "104it [01:56,  1.12s/it]\u001b[A\n",
      "105it [01:57,  1.12s/it]\u001b[A\n",
      "106it [01:58,  1.12s/it]\u001b[A\n",
      "107it [02:00,  1.12s/it]\u001b[A\n",
      "108it [02:01,  1.12s/it]\u001b[A\n",
      "109it [02:02,  1.12s/it]\u001b[A\n",
      "110it [02:03,  1.12s/it]\u001b[A\n",
      "111it [02:04,  1.12s/it]\u001b[A\n",
      "112it [02:05,  1.12s/it]\u001b[A\n",
      "113it [02:06,  1.12s/it]\u001b[A\n",
      "114it [02:07,  1.12s/it]\u001b[A\n",
      "115it [02:08,  1.12s/it]\u001b[A\n",
      "116it [02:10,  1.12s/it]\u001b[A\n",
      "117it [02:11,  1.12s/it]\u001b[A\n",
      "118it [02:12,  1.12s/it]\u001b[A\n",
      "119it [02:13,  1.12s/it]\u001b[A\n",
      "120it [02:14,  1.12s/it]\u001b[A\n",
      "121it [02:15,  1.12s/it]\u001b[A\n",
      "122it [02:16,  1.12s/it]\u001b[A\n",
      "123it [02:17,  1.12s/it]\u001b[A\n",
      "124it [02:19,  1.12s/it]\u001b[A\n",
      "125it [02:20,  1.12s/it]\u001b[A\n",
      "126it [02:21,  1.12s/it]\u001b[A\n",
      "127it [02:22,  1.12s/it]\u001b[A\n",
      "128it [02:23,  1.12s/it]\u001b[A\n",
      "129it [02:24,  1.12s/it]\u001b[A\n",
      "130it [02:25,  1.12s/it]\u001b[A\n",
      "131it [02:26,  1.12s/it]\u001b[A\n",
      "132it [02:27,  1.12s/it]\u001b[A\n",
      "133it [02:29,  1.12s/it]\u001b[A\n",
      "134it [02:30,  1.12s/it]\u001b[A\n",
      "135it [02:31,  1.12s/it]\u001b[A\n",
      "136it [02:32,  1.12s/it]\u001b[A\n",
      "137it [02:33,  1.12s/it]\u001b[A\n",
      "138it [02:34,  1.12s/it]\u001b[A\n",
      "139it [02:35,  1.12s/it]\u001b[A\n",
      "140it [02:36,  1.13s/it]\u001b[A\n",
      "141it [02:38,  1.12s/it]\u001b[A\n",
      "142it [02:39,  1.12s/it]\u001b[A\n",
      "143it [02:40,  1.12s/it]\u001b[A\n",
      "144it [02:41,  1.12s/it]\u001b[A\n",
      "145it [02:42,  1.12s/it]\u001b[A\n",
      "146it [02:43,  1.12s/it]\u001b[A\n",
      "147it [02:44,  1.12s/it]\u001b[A\n",
      "148it [02:45,  1.12s/it]\u001b[A\n",
      "149it [02:47,  1.12s/it]\u001b[A\n",
      "150it [02:48,  1.12s/it]\u001b[A\n",
      "151it [02:49,  1.12s/it]\u001b[A\n",
      "152it [02:50,  1.12s/it]\u001b[A\n",
      "153it [02:51,  1.12s/it]\u001b[A\n",
      "154it [02:52,  1.12s/it]\u001b[A\n",
      "155it [02:53,  1.12s/it]\u001b[A\n",
      "156it [02:54,  1.12s/it]\u001b[A\n",
      "157it [02:55,  1.12s/it]\u001b[A\n",
      "158it [02:57,  1.12s/it]\u001b[A\n",
      "159it [02:58,  1.12s/it]\u001b[A\n",
      "160it [02:59,  1.12s/it]\u001b[A\n",
      "161it [03:00,  1.12s/it]\u001b[A\n",
      "162it [03:01,  1.12s/it]\u001b[A\n",
      "163it [03:02,  1.12s/it]\u001b[A\n",
      "164it [03:03,  1.12s/it]\u001b[A\n",
      "165it [03:04,  1.12s/it]\u001b[A\n",
      "166it [03:06,  1.12s/it]\u001b[A\n",
      "167it [03:07,  1.12s/it]\u001b[A\n",
      "168it [03:08,  1.12s/it]\u001b[A\n",
      "169it [03:09,  1.12s/it]\u001b[A\n",
      "170it [03:10,  1.12s/it]\u001b[A\n",
      "171it [03:11,  1.12s/it]\u001b[A\n",
      "172it [03:12,  1.12s/it]\u001b[A\n",
      "173it [03:13,  1.12s/it]\u001b[A\n",
      "174it [03:14,  1.11s/it]\u001b[A\n",
      "175it [03:16,  1.11s/it]\u001b[A\n",
      "176it [03:17,  1.11s/it]\u001b[A\n",
      "177it [03:18,  1.12s/it]\u001b[A\n",
      "178it [03:19,  1.12s/it]\u001b[A\n",
      "179it [03:20,  1.12s/it]\u001b[A\n",
      "180it [03:21,  1.12s/it]\u001b[A\n",
      "181it [03:22,  1.12s/it]\u001b[A\n",
      "182it [03:23,  1.12s/it]\u001b[A\n",
      "183it [03:25,  1.12s/it]\u001b[A\n",
      "184it [03:26,  1.12s/it]\u001b[A\n",
      "185it [03:27,  1.12s/it]\u001b[A\n",
      "186it [03:28,  1.12s/it]\u001b[A\n",
      "187it [03:29,  1.12s/it]\u001b[A\n",
      "188it [03:30,  1.12s/it]\u001b[A\n",
      "189it [03:31,  1.12s/it]\u001b[A\n",
      "190it [03:32,  1.12s/it]\u001b[A\n",
      "191it [03:34,  1.12s/it]\u001b[A\n",
      "192it [03:35,  1.12s/it]\u001b[A\n",
      "193it [03:36,  1.12s/it]\u001b[A\n",
      "194it [03:37,  1.12s/it]\u001b[A\n",
      "195it [03:38,  1.12s/it]\u001b[A\n",
      "196it [03:39,  1.12s/it]\u001b[A\n",
      "197it [03:40,  1.12s/it]\u001b[A\n",
      "198it [03:41,  1.12s/it]\u001b[A\n",
      "199it [03:42,  1.12s/it]\u001b[A\n",
      "200it [03:44,  1.12s/it]\u001b[A\n",
      "201it [03:45,  1.12s/it]\u001b[A\n",
      "202it [03:46,  1.12s/it]\u001b[A\n",
      "203it [03:47,  1.12s/it]\u001b[A\n",
      "204it [03:48,  1.12s/it]\u001b[A\n",
      "205it [03:49,  1.12s/it]\u001b[A\n",
      "206it [03:50,  1.12s/it]\u001b[A\n",
      "207it [03:51,  1.12s/it]\u001b[A\n",
      "208it [03:53,  1.12s/it]\u001b[A\n",
      "209it [03:54,  1.12s/it]\u001b[A\n",
      "210it [03:55,  1.12s/it]\u001b[A\n",
      "211it [03:56,  1.12s/it]\u001b[A\n",
      "212it [03:57,  1.13s/it]\u001b[A\n",
      "213it [03:58,  1.12s/it]\u001b[A\n",
      "214it [03:59,  1.12s/it]\u001b[A\n",
      "215it [04:00,  1.12s/it]\u001b[A\n",
      "216it [04:02,  1.12s/it]\u001b[A\n",
      "217it [04:03,  1.12s/it]\u001b[A\n",
      "218it [04:04,  1.12s/it]\u001b[A\n",
      "219it [04:05,  1.12s/it]\u001b[A\n",
      "220it [04:06,  1.12s/it]\u001b[A\n",
      "221it [04:07,  1.12s/it]\u001b[A\n",
      "222it [04:08,  1.12s/it]\u001b[A\n",
      "223it [04:09,  1.12s/it]\u001b[A\n",
      "224it [04:10,  1.13s/it]\u001b[A\n",
      "225it [04:12,  1.13s/it]\u001b[A\n",
      "226it [04:13,  1.12s/it]\u001b[A\n",
      "227it [04:14,  1.13s/it]\u001b[A\n",
      "228it [04:15,  1.12s/it]\u001b[A\n",
      "229it [04:16,  1.12s/it]\u001b[A\n",
      "230it [04:17,  1.12s/it]\u001b[A\n",
      "231it [04:18,  1.12s/it]\u001b[A\n",
      "232it [04:19,  1.12s/it]\u001b[A\n",
      "233it [04:21,  1.12s/it]\u001b[A\n",
      "234it [04:22,  1.12s/it]\u001b[A\n",
      "235it [04:23,  1.12s/it]\u001b[A\n",
      "236it [04:24,  1.12s/it]\u001b[A\n",
      "237it [04:25,  1.12s/it]\u001b[A\n",
      "238it [04:26,  1.11s/it]\u001b[A\n",
      "239it [04:27,  1.12s/it]\u001b[A\n",
      "240it [04:28,  1.12s/it]\u001b[A\n",
      "241it [04:30,  1.12s/it]\u001b[A\n",
      "242it [04:31,  1.12s/it]\u001b[A\n",
      "243it [04:32,  1.12s/it]\u001b[A\n",
      "244it [04:33,  1.12s/it]\u001b[A\n",
      "245it [04:34,  1.12s/it]\u001b[A\n",
      "246it [04:35,  1.12s/it]\u001b[A\n",
      "247it [04:36,  1.12s/it]\u001b[A\n",
      "248it [04:37,  1.12s/it]\u001b[A\n",
      "249it [04:38,  1.12s/it]\u001b[A\n",
      "250it [04:40,  1.12s/it]\u001b[A\n",
      "251it [04:41,  1.12s/it]\u001b[A\n",
      "252it [04:42,  1.12s/it]\u001b[A\n",
      "253it [04:43,  1.12s/it]\u001b[A\n",
      "254it [04:44,  1.12s/it]\u001b[A\n",
      "255it [04:45,  1.12s/it]\u001b[A\n",
      "256it [04:46,  1.12s/it]\u001b[A\n",
      "257it [04:47,  1.12s/it]\u001b[A\n",
      "258it [04:49,  1.12s/it]\u001b[A\n",
      "259it [04:50,  1.12s/it]\u001b[A\n",
      "260it [04:51,  1.12s/it]\u001b[A\n",
      "261it [04:52,  1.12s/it]\u001b[A\n",
      "262it [04:53,  1.12s/it]\u001b[A\n",
      "263it [04:54,  1.12s/it]\u001b[A\n",
      "264it [04:55,  1.12s/it]\u001b[A\n",
      "265it [04:56,  1.12s/it]\u001b[A\n",
      "266it [04:58,  1.12s/it]\u001b[A\n",
      "267it [04:59,  1.12s/it]\u001b[A\n",
      "268it [05:00,  1.12s/it]\u001b[A\n",
      "269it [05:01,  1.12s/it]\u001b[A\n",
      "270it [05:02,  1.12s/it]\u001b[A\n",
      "271it [05:03,  1.12s/it]\u001b[A\n",
      "272it [05:04,  1.12s/it]\u001b[A\n",
      "273it [05:05,  1.12s/it]\u001b[A\n",
      "274it [05:06,  1.12s/it]\u001b[A\n",
      "275it [05:08,  1.12s/it]\u001b[A\n",
      "276it [05:09,  1.12s/it]\u001b[A\n",
      "277it [05:10,  1.12s/it]\u001b[A\n",
      "278it [05:11,  1.12s/it]\u001b[A\n",
      "279it [05:12,  1.12s/it]\u001b[A\n",
      "280it [05:13,  1.11s/it]\u001b[A\n",
      "281it [05:14,  1.11s/it]\u001b[A\n",
      "282it [05:15,  1.12s/it]\u001b[A\n",
      "283it [05:17,  1.12s/it]\u001b[A\n",
      "284it [05:18,  1.11s/it]\u001b[A\n",
      "285it [05:19,  1.11s/it]\u001b[A\n",
      "286it [05:20,  1.11s/it]\u001b[A\n",
      "287it [05:21,  1.12s/it]\u001b[A\n",
      "288it [05:22,  1.11s/it]\u001b[A\n",
      "289it [05:23,  1.12s/it]\u001b[A\n",
      "290it [05:24,  1.12s/it]\u001b[A\n",
      "291it [05:25,  1.11s/it]\u001b[A\n",
      "292it [05:27,  1.11s/it]\u001b[A\n",
      "293it [05:28,  1.11s/it]\u001b[A\n",
      "294it [05:29,  1.11s/it]\u001b[A\n",
      "295it [05:30,  1.11s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "296it [05:31,  1.11s/it]\u001b[A\n",
      "297it [05:32,  1.12s/it]\u001b[A\n",
      "298it [05:33,  1.12s/it]\u001b[A\n",
      "299it [05:34,  1.12s/it]\u001b[A\n",
      "300it [05:36,  1.12s/it]\u001b[A\n",
      "301it [05:37,  1.12s/it]\u001b[A\n",
      "302it [05:38,  1.12s/it]\u001b[A\n",
      "303it [05:39,  1.12s/it]\u001b[A\n",
      "304it [05:40,  1.12s/it]\u001b[A\n",
      "305it [05:41,  1.12s/it]\u001b[A\n",
      "306it [05:42,  1.12s/it]\u001b[A\n",
      "307it [05:43,  1.12s/it]\u001b[A\n",
      "308it [05:44,  1.12s/it]\u001b[A\n",
      "309it [05:46,  1.12s/it]\u001b[A\n",
      "310it [05:47,  1.12s/it]\u001b[A\n",
      "311it [05:48,  1.12s/it]\u001b[A\n",
      "312it [05:49,  1.11s/it]\u001b[A\n",
      "313it [05:50,  1.12s/it]\u001b[A\n",
      "314it [05:51,  1.11s/it]\u001b[A\n",
      "315it [05:52,  1.11s/it]\u001b[A\n",
      "316it [05:53,  1.11s/it]\u001b[A\n",
      "317it [05:54,  1.11s/it]\u001b[A\n",
      "318it [05:56,  1.11s/it]\u001b[A\n",
      "319it [05:57,  1.12s/it]\u001b[A\n",
      "320it [05:58,  1.12s/it]\u001b[A\n",
      "321it [05:59,  1.12s/it]\u001b[A\n",
      "322it [06:00,  1.11s/it]\u001b[A\n",
      "323it [06:01,  1.11s/it]\u001b[A\n",
      "324it [06:02,  1.11s/it]\u001b[A\n",
      "325it [06:03,  1.11s/it]\u001b[A\n",
      "326it [06:05,  1.12s/it]\u001b[A\n",
      "327it [06:06,  1.12s/it]\u001b[A\n",
      "328it [06:07,  1.12s/it]\u001b[A\n",
      "329it [06:08,  1.12s/it]\u001b[A\n",
      "330it [06:09,  1.12s/it]\u001b[A\n",
      "331it [06:10,  1.11s/it]\u001b[A\n",
      "332it [06:11,  1.11s/it]\u001b[A\n",
      "333it [06:12,  1.11s/it]\u001b[A\n",
      "334it [06:13,  1.11s/it]\u001b[A\n",
      "335it [06:15,  1.11s/it]\u001b[A\n",
      "336it [06:16,  1.11s/it]\u001b[A\n",
      "337it [06:17,  1.12s/it]\u001b[A\n",
      "338it [06:18,  1.12s/it]\u001b[A\n",
      "339it [06:19,  1.12s/it]\u001b[A\n",
      "340it [06:20,  1.11s/it]\u001b[A\n",
      "341it [06:21,  1.11s/it]\u001b[A\n",
      "342it [06:22,  1.11s/it]\u001b[A\n",
      "343it [06:23,  1.11s/it]\u001b[A\n",
      "344it [06:25,  1.11s/it]\u001b[A\n",
      "345it [06:26,  1.11s/it]\u001b[A\n",
      "346it [06:27,  1.12s/it]\u001b[A\n",
      "347it [06:28,  1.11s/it]\u001b[A\n",
      "348it [06:29,  1.11s/it]\u001b[A\n",
      "349it [06:30,  1.11s/it]\u001b[A\n",
      "350it [06:31,  1.11s/it]\u001b[A\n",
      "351it [06:32,  1.11s/it]\u001b[A\n",
      "352it [06:33,  1.11s/it]\u001b[A\n",
      "353it [06:35,  1.11s/it]\u001b[A\n",
      "354it [06:36,  1.11s/it]\u001b[A\n",
      "355it [06:37,  1.11s/it]\u001b[A\n",
      "356it [06:38,  1.11s/it]\u001b[A\n",
      "357it [06:39,  1.11s/it]\u001b[A\n",
      "358it [06:40,  1.11s/it]\u001b[A\n",
      "359it [06:41,  1.11s/it]\u001b[A\n",
      "360it [06:42,  1.11s/it]\u001b[A\n",
      "361it [06:44,  1.12s/it]\u001b[A\n",
      "362it [06:45,  1.12s/it]\u001b[A\n",
      "363it [06:46,  1.12s/it]\u001b[A\n",
      "364it [06:47,  1.12s/it]\u001b[A\n",
      "365it [06:48,  1.12s/it]\u001b[A\n",
      "366it [06:49,  1.12s/it]\u001b[A\n",
      "367it [06:50,  1.12s/it]\u001b[A\n",
      "368it [06:51,  1.12s/it]\u001b[A\n",
      "369it [06:52,  1.12s/it]\u001b[A\n",
      "370it [06:54,  1.12s/it]\u001b[A\n",
      "371it [06:55,  1.12s/it]\u001b[A\n",
      "372it [06:56,  1.12s/it]\u001b[A\n",
      "373it [06:57,  1.12s/it]\u001b[A\n",
      "374it [06:58,  1.12s/it]\u001b[A\n",
      "375it [06:59,  1.12s/it]\u001b[A\n",
      "376it [07:00,  1.12s/it]\u001b[A\n",
      "377it [07:01,  1.12s/it]\u001b[A\n",
      "378it [07:03,  1.12s/it]\u001b[A\n",
      "379it [07:04,  1.12s/it]\u001b[A\n",
      "380it [07:05,  1.13s/it]\u001b[A\n",
      "381it [07:06,  1.12s/it]\u001b[A\n",
      "382it [07:07,  1.12s/it]\u001b[A\n",
      "383it [07:08,  1.11s/it]\u001b[A\n",
      "384it [07:09,  1.11s/it]\u001b[A\n",
      "385it [07:10,  1.11s/it]\u001b[A\n",
      "386it [07:11,  1.12s/it]\u001b[A\n",
      "387it [07:13,  1.12s/it]\u001b[A\n",
      "388it [07:14,  1.12s/it]\u001b[A\n",
      "389it [07:15,  1.12s/it]\u001b[A\n",
      "390it [07:16,  1.12s/it]\u001b[A\n",
      "391it [07:17,  1.12s/it]\u001b[A\n",
      "392it [07:18,  1.12s/it]\u001b[A\n",
      "393it [07:19,  1.12s/it]\u001b[A\n",
      "394it [07:20,  1.12s/it]\u001b[A\n",
      "395it [07:22,  1.12s/it]\u001b[A\n",
      "396it [07:23,  1.12s/it]\u001b[A\n",
      "397it [07:24,  1.12s/it]\u001b[A\n",
      "398it [07:25,  1.12s/it]\u001b[A\n",
      "399it [07:26,  1.12s/it]\u001b[A\n",
      "400it [07:27,  1.12s/it]\u001b[A\n",
      "401it [07:28,  1.12s/it]\u001b[A\n",
      "402it [07:29,  1.12s/it]\u001b[A\n",
      "403it [07:30,  1.12s/it]\u001b[A\n",
      "404it [07:32,  1.12s/it]\u001b[A\n",
      "405it [07:33,  1.12s/it]\u001b[A\n",
      "406it [07:34,  1.12s/it]\u001b[A\n",
      "407it [07:35,  1.12s/it]\u001b[A\n",
      "408it [07:36,  1.12s/it]\u001b[A\n",
      "409it [07:37,  1.12s/it]\u001b[A\n",
      "410it [07:38,  1.12s/it]\u001b[A\n",
      "411it [07:39,  1.12s/it]\u001b[A\n",
      "412it [07:41,  1.12s/it]\u001b[A\n",
      "413it [07:42,  1.12s/it]\u001b[A\n",
      "414it [07:43,  1.12s/it]\u001b[A\n",
      "415it [07:44,  1.12s/it]\u001b[A\n",
      "416it [07:45,  1.12s/it]\u001b[A\n",
      "417it [07:46,  1.12s/it]\u001b[A\n",
      "418it [07:47,  1.12s/it]\u001b[A\n",
      "419it [07:48,  1.12s/it]\u001b[A\n",
      "420it [07:50,  1.12s/it]\u001b[A\n",
      "421it [07:51,  1.12s/it]\u001b[A\n",
      "422it [07:52,  1.12s/it]\u001b[A\n",
      "423it [07:53,  1.11s/it]\u001b[A\n",
      "424it [07:54,  1.11s/it]\u001b[A\n",
      "425it [07:55,  1.11s/it]\u001b[A\n",
      "426it [07:56,  1.11s/it]\u001b[A\n",
      "427it [07:57,  1.12s/it]\u001b[A\n",
      "428it [07:58,  1.12s/it]\u001b[A\n",
      "429it [08:00,  1.12s/it]\u001b[A\n",
      "430it [08:01,  1.12s/it]\u001b[A\n",
      "431it [08:02,  1.12s/it]\u001b[A\n",
      "432it [08:03,  1.12s/it]\u001b[A\n",
      "433it [08:04,  1.12s/it]\u001b[A\n",
      "434it [08:05,  1.12s/it]\u001b[A\n",
      "435it [08:06,  1.12s/it]\u001b[A\n",
      "436it [08:07,  1.12s/it]\u001b[A\n",
      "437it [08:08,  1.12s/it]\u001b[A\n",
      "438it [08:10,  1.11s/it]\u001b[A\n",
      "439it [08:11,  1.11s/it]\u001b[A\n",
      "440it [08:12,  1.12s/it]\u001b[A\n",
      "441it [08:13,  1.12s/it]\u001b[A\n",
      "442it [08:14,  1.12s/it]\u001b[A\n",
      "443it [08:15,  1.12s/it]\u001b[A\n",
      "444it [08:16,  1.12s/it]\u001b[A\n",
      "445it [08:17,  1.12s/it]\u001b[A\n",
      "446it [08:19,  1.12s/it]\u001b[A\n",
      "447it [08:20,  1.12s/it]\u001b[A\n",
      "448it [08:21,  1.11s/it]\u001b[A\n",
      "449it [08:22,  1.11s/it]\u001b[A\n",
      "450it [08:23,  1.11s/it]\u001b[A\n",
      "451it [08:24,  1.11s/it]\u001b[A\n",
      "452it [08:25,  1.11s/it]\u001b[A\n",
      "453it [08:26,  1.11s/it]\u001b[A\n",
      "454it [08:27,  1.12s/it]\u001b[A\n",
      "455it [08:29,  1.12s/it]\u001b[A\n",
      "456it [08:30,  1.12s/it]\u001b[A\n",
      "457it [08:31,  1.12s/it]\u001b[A\n",
      "458it [08:32,  1.12s/it]\u001b[A\n",
      "459it [08:33,  1.12s/it]\u001b[A\n",
      "460it [08:34,  1.11s/it]\u001b[A\n",
      "461it [08:35,  1.11s/it]\u001b[A\n",
      "462it [08:36,  1.12s/it]\u001b[A\n",
      "463it [08:37,  1.11s/it]\u001b[A\n",
      "464it [08:39,  1.12s/it]\u001b[A\n",
      "465it [08:40,  1.12s/it]\u001b[A\n",
      "466it [08:41,  1.12s/it]\u001b[A\n",
      "467it [08:42,  1.12s/it]\u001b[A\n",
      "468it [08:43,  1.12s/it]\u001b[A\n",
      "469it [08:44,  1.12s/it]\u001b[A\n",
      "470it [08:45,  1.11s/it]\u001b[A\n",
      "471it [08:46,  1.12s/it]\u001b[A\n",
      "472it [08:48,  1.12s/it]\u001b[A\n",
      "473it [08:49,  1.12s/it]\u001b[A\n",
      "474it [08:50,  1.12s/it]\u001b[A\n",
      "475it [08:51,  1.12s/it]\u001b[A\n",
      "476it [08:52,  1.12s/it]\u001b[A\n",
      "477it [08:53,  1.12s/it]\u001b[A\n",
      "478it [08:54,  1.12s/it]\u001b[A\n",
      "479it [08:55,  1.12s/it]\u001b[A\n",
      "480it [08:56,  1.12s/it]\u001b[A\n",
      "481it [08:58,  1.12s/it]\u001b[A\n",
      "482it [08:59,  1.12s/it]\u001b[A\n",
      "483it [09:00,  1.12s/it]\u001b[A\n",
      "484it [09:01,  1.12s/it]\u001b[A\n",
      "485it [09:02,  1.12s/it]\u001b[A\n",
      "486it [09:03,  1.12s/it]\u001b[A\n",
      "487it [09:04,  1.11s/it]\u001b[A\n",
      "488it [09:05,  1.11s/it]\u001b[A\n",
      "489it [09:07,  1.12s/it]\u001b[A\n",
      "490it [09:08,  1.12s/it]\u001b[A\n",
      "491it [09:09,  1.11s/it]\u001b[A\n",
      "492it [09:10,  1.11s/it]\u001b[A\n",
      "493it [09:11,  1.11s/it]\u001b[A\n",
      "494it [09:12,  1.11s/it]\u001b[A\n",
      "495it [09:13,  1.11s/it]\u001b[A\n",
      "496it [09:14,  1.11s/it]\u001b[A\n",
      "497it [09:15,  1.11s/it]\u001b[A\n",
      "498it [09:17,  1.11s/it]\u001b[A\n",
      "499it [09:18,  1.12s/it]\u001b[A\n",
      "500it [09:19,  1.12s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes 19\n",
      "===>road:\t82.9\n",
      "===>sidewalk:\t43.08\n",
      "===>building:\t78.06\n",
      "===>wall:\t9.29\n",
      "===>fence:\t0.56\n",
      "===>pole:\t28.23\n",
      "===>light:\t9.13\n",
      "===>sign:\t14.45\n",
      "===>vegetation:\t77.02\n",
      "===>terrain:\t0.0\n",
      "===>sky:\t83.49\n",
      "===>person:\t58.13\n",
      "===>rider:\t25.9\n",
      "===>car:\t71.93\n",
      "===>truck:\t0.0\n",
      "===>bus:\t38.02\n",
      "===>train:\t0.0\n",
      "===>motocycle:\t29.43\n",
      "===>bicycle:\t31.16\n",
      "===> mIoU19: 35.83\n",
      "===> mIoU16: 42.55\n",
      "===> mIoU13: 49.44\n"
     ]
    }
   ],
   "source": [
    "testing_entr, mIoU_ = run_time_evaluation.main(Base.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(Base.args.Expriment_name+'entr_record.npy', np.array(record_entropy))\n",
    "np.save(Base.args.Expriment_name+'Iou_record.npy', np.array(record_mIoU_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[238.91925, 211.53044, 201.52953, 181.916, 171.4761, 170.83728]\n"
     ]
    }
   ],
   "source": [
    "print(record_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPMuy8oQQqI3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1Pdy0EpQqI7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fwAnfUf9QqI-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UVy9L3HOQqJB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGKILoFmQqJE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cd1CV0AGQqJH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IESPUiBsQqJJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "Fahxt6z2QqJM"
   },
   "source": [
    "new flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a9Da7BK-QqJP"
   },
   "outputs": [],
   "source": [
    "run_time_evaluation.main(Base.model,source_priros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDKoJhJbQqJT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPkUmicrQqJW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8DjGNuWQqJZ"
   },
   "outputs": [],
   "source": [
    "sourceloader, targetloader = CreateSrcDataLoader(Base.args), CreateTrgDataLoader(Base.args)\n",
    "targetloader_iter, sourceloader_iter = iter(targetloader), iter(sourceloader)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GneykW4OQqJc"
   },
   "outputs": [],
   "source": [
    "src_img, src_lbl, _, _ = sourceloader_iter.next()\n",
    "src_img=src_img.cpu().data[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "brEgYqxyQqJf"
   },
   "outputs": [],
   "source": [
    "plt.imshow(src_img.reshape(720,1280,3)/255,interpolation='nearest')\n",
    "plt.grid(False)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g74RszJKQqJl"
   },
   "outputs": [],
   "source": [
    "trg_img, trg_lbl, _, _ = targetloader_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIu86pmEQqJq"
   },
   "outputs": [],
   "source": [
    "print(src_lbl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "JqRmUY1LQqJu"
   },
   "source": [
    "\n",
    "\n",
    "Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ac1EbFwQqJw"
   },
   "outputs": [],
   "source": [
    "def visualize(temp, plot=True):\n",
    "    r = temp.copy()\n",
    "    g = temp.copy()\n",
    "    b = temp.copy()\n",
    "    for l in range(0,20):\n",
    "        r[temp==l]=label_colours[l,0]\n",
    "        g[temp==l]=label_colours[l,1]\n",
    "        b[temp==l]=label_colours[l,2]\n",
    "\n",
    "    rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n",
    "    rgb[:,:,0] = (r/255.0)#[:,:,0]\n",
    "    rgb[:,:,1] = (g/255.0)#[:,:,1]\n",
    "    rgb[:,:,2] = (b/255.0)#[:,:,2]\n",
    "    if plot:\n",
    "        plt.imshow(rgb)\n",
    "    else:\n",
    "        return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3QyNYAEuQqJz"
   },
   "outputs": [],
   "source": [
    "road = (128, 64,128)\n",
    "side_walk = (232, 35,244)\n",
    "building = (70, 70, 70)\n",
    "wall = (102,102,156)\n",
    "fence = (190,153,153)\n",
    "pole = (153,153,153)\n",
    "trafic_lights = (250,170, 30)\n",
    "trafic_sign = (220,220,  0)\n",
    "vegitation = (107,142, 35)\n",
    "terrain = (152,251,152)\n",
    "sky = (70,130,180)\n",
    "person = (220, 20, 60)\n",
    "rider = (255,  0,  0)\n",
    "car = ( 0,  0,142)\n",
    "truck = (0,  0, 70)\n",
    "bus = ( 0, 60,100)\n",
    "train = ( 0, 80,100)\n",
    "motorcycle = (0,  0,230)\n",
    "bicycle = (119, 11, 32)\n",
    "else_ = ( 0,  0,  0)\n",
    "\n",
    "\n",
    "\n",
    "label_colours = np.array([road, side_walk, building, wall,fence,\n",
    "                          pole, trafic_lights , trafic_sign , vegitation,  terrain ,  sky,  person, rider , car , truck ,bus  , train , motorcycle, bicycle ,else_  ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19AdY-iwQqJ6"
   },
   "source": [
    "Entropy threshold for filtering of each class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "36QiSjggQqJ7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# commutes = pd.DataFrame({'Entropy Threshold':Base.entropy_th_class.reshape(19)})   #Base.entropy_th_class.reshape(19)s\n",
    "\n",
    "# # commutes.plot(grid=True, bins=20, rwidth=0.9,\n",
    "# #                    color='#607c8e')\n",
    "# # plt.title('Commute Times for 1,000 Commuters')\n",
    "# # plt.xlabel('Counts')\n",
    "# # plt.ylabel('Commute Time')\n",
    "# # plt.grid(axis='y', alpha=0.75)\n",
    "\n",
    "# ax = commutes.plot(grid=True,\n",
    "#                    color='#607c8e' ,kind='bar', figsize=(10,4)) # bar plots are categorical\n",
    "# ax.xaxis.set_visible(False) # table heading and x-labels over-printing\n",
    "\n",
    "# plt.title('Entropy threshold of each class')\n",
    "# plt.xlabel('Counts')\n",
    "# plt.ylabel('Threshold')\n",
    "\n",
    "# # add the ticks and labels to the plot\n",
    "# ax.set_xticks(xticks)\n",
    "\n",
    "# plt.grid(axis='y', alpha=0.75)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAaGQB0gQqJ9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(Base.entropy_th_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LuK6El7bQqKB"
   },
   "outputs": [],
   "source": [
    "class Analysis():\n",
    "    def __init__(self,model_loader):\n",
    "        self.args =model_loader.args\n",
    "        self.model_name =model_loader.model_name\n",
    "        self.model = model_loader.model\n",
    "        self.optimizer = model_loader.optimizer\n",
    "    def Show(self, rl_img,Y_pred,X_Patch_resize,Y_Patch_resize,Y_Patch_resize_div):\n",
    "        print(\"********Input Image*************\")\n",
    "        Plot_img(rl_img)\n",
    "\n",
    "        print(\"********Prediction*************\")\n",
    "        a =np.argmax(Y_pred.T,axis=0)\n",
    "        true_lab = visualize(a.T.reshape((IMG_H,IMG_W)), False)\n",
    "        Plot_img(true_lab)\n",
    "        \n",
    "        print(\"********Patch*************\")\n",
    "        Plot_img(X_Patch_resize)\n",
    "        \n",
    "        print(\"********Patch Pseudo labels*************\")\n",
    "        a =np.argmax(Y_Patch_resize.T,axis=0)\n",
    "        true_lab = visualize(a.T.reshape((IMG_H,IMG_W)), False)\n",
    "        Plot_img(true_lab)\n",
    "        \n",
    "        print(\"********Patch Pseudo labels with division*************\")\n",
    "        a =np.argmax(Y_Patch_resize_div.T,axis=0)\n",
    "        true_lab = visualize(a.T.reshape((IMG_H,IMG_W)), False)\n",
    "        Plot_img(true_lab)\n",
    "        \n",
    "    def Final_image_results(self, num_of_samples):\n",
    "        self.args.data_label_folder_target = None\n",
    "        self.args.shuffel_ = False\n",
    "        self.args.data_dir_target = root_base +'/dataset/cityscapes'\n",
    "        self.args.data_list_target = sorted_list\n",
    "        self.model.eval()\n",
    "        self.model.cuda()    \n",
    "        \n",
    "        targetloader = CreateTrgDataLoader(self.args)\n",
    "        \n",
    "        print(\"***********Results output***********\")\n",
    "        \n",
    "        for index, batch in enumerate(targetloader):\n",
    "            print(\"###################################\")\n",
    "            if(index > num_of_samples):\n",
    "                break\n",
    "            \n",
    "            image, _, name, rl_img = batch\n",
    "            output = self.model(Variable(image).cuda())\n",
    "            output = nn.functional.softmax(output, dim=1)\n",
    "            rl_img = rl_img.cpu().data[0].numpy()/255.0\n",
    "            output=output.cpu().data[0].numpy()\n",
    "            Y_p = keras_out(output)    # later delete this line man\n",
    "\n",
    "                    \n",
    "            \n",
    "            \n",
    "            Y_pred = keras_out(output)\n",
    "            \n",
    "            ################################################\n",
    "#             map_ = np.zeros((IMG_H,IMG_W))\n",
    "#             SE = self_entropy(Y_pred)\n",
    "            \n",
    "#             map_[SE >= entropy_th] =  0\n",
    "#             map_[SE < entropy_th] =  1\n",
    "            \n",
    "            ######################\n",
    "            print(name)\n",
    "            print(\"********Target image*************\")\n",
    "            Plot_img(rl_img)\n",
    "            print(\"********whole Prediction*************\")\n",
    "            a =np.argmax(Y_pred.T,axis=0)\n",
    "            true_lab = visualize(a.T.reshape((IMG_H,IMG_W)), False)\n",
    "            Plot_img(true_lab)\n",
    "            \n",
    "            \n",
    "\n",
    "        \n",
    "    \n",
    "    def Pseudo_labels_analysis(self, num_of_samples):\n",
    "        self.args.data_label_folder_target = None\n",
    "        self.args.shuffel_ = False\n",
    "        self.args.data_dir_target = root_base +'/dataset/cityscapes'\n",
    "        self.args.data_list_target = sorted_list\n",
    "        self.model.eval()\n",
    "        self.model.cuda()    \n",
    "        \n",
    "        targetloader = CreateTrgDataLoader(self.args)\n",
    "        \n",
    "        print(\"***********Testing Pseudo labels***********\")\n",
    "        \n",
    "        for index, batch in enumerate(targetloader):\n",
    "            print(\"###################################\")\n",
    "            if(index > num_of_samples):\n",
    "                break\n",
    "            \n",
    "            image, _, name, rl_img = batch\n",
    "            output = self.model(Variable(image).cuda())\n",
    "            output = nn.functional.softmax(output, dim=1)\n",
    "            rl_img = rl_img.cpu().data[0].numpy()/255.0\n",
    "            output=output.cpu().data[0].numpy()\n",
    "            Y_p = keras_out(output)    # later delete this line man\n",
    "            if(balance_):\n",
    "                wei = (1 - weight_mat )** d1\n",
    "                output = np.multiply(output,wei)\n",
    "                    \n",
    "            \n",
    "            \n",
    "            Y_pred = keras_out(output)\n",
    "            \n",
    "            ################################################\n",
    "            map_ = np.zeros((IMG_H,IMG_W))\n",
    "            SE = self_entropy(Y_pred)\n",
    "            \n",
    "            map_[SE >= entropy_th] =  0\n",
    "            map_[SE < entropy_th] =  1\n",
    "            \n",
    "            ######################\n",
    "            print(\"********Target image*************\")\n",
    "            Plot_img(rl_img)\n",
    "            print(\"********whole Prediction*************\")\n",
    "            a =np.argmax(Y_pred.T,axis=0)\n",
    "            true_lab = visualize(a.T.reshape((IMG_H,IMG_W)), False)\n",
    "            Plot_img(true_lab)\n",
    "            print(\"********whole Filtering map*************\")\n",
    "            plt.imshow(map_.reshape(IMG_H,IMG_W),cmap='gray')\n",
    "            plt.grid(False)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            for patch in range(patches):\n",
    "                \n",
    "\n",
    "                point_X_s = 512\n",
    "                point_Y_s = 256\n",
    "                \n",
    "                point_X = random.randint(0, IMG_W-point_X_s)\n",
    "                point_Y = random.randint(0, IMG_H - point_Y_s)\n",
    "\n",
    "            \n",
    "                x_PATCH =  rl_img[ point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(point_Y_s,point_X_s,3)\n",
    "                y_PATCH =  Y_pred[0, point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(1,point_Y_s,point_X_s,19)\n",
    "                map_patch = map_[point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(point_Y_s,point_X_s)\n",
    "   \n",
    "                X_Patch_resize = resize(x_PATCH, (IMG_H, IMG_W), anti_aliasing=False)\n",
    "                Y_Patch_resize = resize(y_PATCH, (1,IMG_H, IMG_W), anti_aliasing=False)\n",
    "                map_patch_re = resize(map_patch, (IMG_H, IMG_W), anti_aliasing=False)\n",
    "        \n",
    "                \n",
    "\n",
    "                #f.write(str(count+patch)+\".png\"+'\\n')\n",
    "                #self.save_data(X_Patch_resize, Y_Patch_resize.reshape(IMG_H,IMG_W,19), generated_data,(count+patch),map_)\n",
    "                \n",
    "            #count+=patches + 1\n",
    "        #print(\"*****************END****************\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            ########################################################\n",
    "                print(\"********patch*************\")\n",
    "                Plot_img(X_Patch_resize)\n",
    "\n",
    "                print(\"******** patch Prediction*************\")\n",
    "                a =np.argmax(Y_Patch_resize.T,axis=0)\n",
    "                true_lab = visualize(a.T.reshape((IMG_H,IMG_W)), False)\n",
    "                Plot_img(true_lab)\n",
    "            \n",
    "#             print(\"********Prediction after balance*************\")\n",
    "#             a =np.argmax(Y_pred.T,axis=0)\n",
    "#             true_lab = visualize(a.T.reshape((IMG_H,IMG_W)), False)\n",
    "#             Plot_img(true_lab)\n",
    "            \n",
    "#             print(\"********Self entropy*************\")\n",
    "#             plt.imshow(SE.reshape(IMG_H,IMG_W),interpolation='nearest')\n",
    "#             plt.grid(False)\n",
    "#             plt.axis('off')\n",
    "#             plt.show()\n",
    "            \n",
    "                print(\"******** patch Filtering map*************\")\n",
    "                plt.imshow(map_patch_re.reshape(IMG_H,IMG_W),cmap='gray')\n",
    "                plt.grid(False)\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             h = random.randint(16, 32)\n",
    "#             point_X_s = int(32 * h)\n",
    "#             point_Y_s = int(point_X_s/2)\n",
    "\n",
    "#             point_X = random.randint(0, IMG_W-point_X_s)\n",
    "#             point_Y = random.randint(0, IMG_H - point_Y_s)\n",
    "\n",
    "\n",
    "#             x_PATCH =  rl_img[ point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(point_Y_s,point_X_s,3)\n",
    "#             y_PATCH =  Y_pred[0, point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(1,point_Y_s,point_X_s,19)\n",
    "\n",
    "#             X_Patch_resize = resize(x_PATCH, (IMG_H, IMG_W), anti_aliasing=True)\n",
    "#             Y_Patch_resize = resize(y_PATCH, (1,IMG_H, IMG_W), anti_aliasing=True)\n",
    "            \n",
    "            \n",
    "# #             map_1 = weights + epsilon   \n",
    "# #             Y_pred_divide = np.divide(Y_pred,map_1)\n",
    "#             output = np.divide(output,blurred)  \n",
    "#             Y_pred_divide = keras_out(output)\n",
    "            \n",
    "#             y_PATCH_div =  Y_pred_divide[0, point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(1,point_Y_s,point_X_s,19)\n",
    "#             Y_Patch_resize_div = resize(y_PATCH_div, (1,IMG_H, IMG_W), anti_aliasing=True)\n",
    "            \n",
    "\n",
    "#             self.Show(rl_img,Y_pred,X_Patch_resize,Y_Patch_resize,Y_Patch_resize_div)\n",
    "        \n",
    "            print(\"###################################\")\n",
    "            \n",
    "    def Pseudo_labels_analysis_2(self, num_of_samples):\n",
    "        self.args.data_label_folder_target = None\n",
    "        self.args.shuffel_ = False\n",
    "        self.args.data_dir_target = root_base +'/dataset/cityscapes'\n",
    "        self.args.data_list_target = sorted_list\n",
    "        self.model.eval()\n",
    "        self.model.cuda()    \n",
    "        \n",
    "        targetloader = CreateTrgDataLoader(self.args)\n",
    "        \n",
    "        print(\"***********Testing Pseudo labels***********\")\n",
    "        \n",
    "        for index, batch in enumerate(targetloader):\n",
    "            print(\"###################################\")\n",
    "            if(index > num_of_samples):\n",
    "                break\n",
    "            \n",
    "            image, _, name, rl_img = batch\n",
    "            output = self.model(Variable(image).cuda())\n",
    "            output = nn.functional.softmax(output, dim=1)\n",
    "            rl_img = rl_img.cpu().data[0].numpy()/255.0\n",
    "            output=output.cpu().data[0].numpy()\n",
    "            Y_p = keras_out(output)    # later delete this line man\n",
    "            \n",
    "            image=image.cpu().data[0].numpy()\n",
    "            image = np.rollaxis(image, axis = -1)\n",
    "            image = np.rollaxis(image, axis = -1)\n",
    "            Y_pred = keras_out(output)\n",
    "            \n",
    "            ################################################\n",
    "            SE = self_entropy(Y_pred)\n",
    "            ########################################################\n",
    "            Plot_img(rl_img)\n",
    "          \n",
    "            print(\"******** full image Prediction*************\")\n",
    "            a =np.argmax(Y_pred.T,axis=0)\n",
    "            true_lab = visualize(a.T.reshape((IMG_H,IMG_W)), False)\n",
    "            Plot_img(true_lab)\n",
    "            \n",
    "            print(\"********Self entropy*************\")\n",
    "            plt.imshow(SE.reshape(IMG_H,IMG_W),interpolation='nearest')\n",
    "            plt.grid(False)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            #################################################\n",
    "            rl_patch = []\n",
    "            se_Main = []\n",
    "            se_Patch = []\n",
    "            se_diff=[]\n",
    "            for patch in range(patches):\n",
    "                \n",
    "\n",
    "                point_X_s = 512\n",
    "                point_Y_s = 256\n",
    "                \n",
    "                point_X = random.randint(0, IMG_W-point_X_s)\n",
    "                point_Y = random.randint(0, IMG_H - point_Y_s)\n",
    "\n",
    "                real_patch =  rl_img[ point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(point_Y_s,point_X_s,3)\n",
    "               \n",
    "                x_PATCH =  image[ point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(point_Y_s,point_X_s,3)\n",
    "                y_PATCH =  Y_pred[0, point_Y:point_Y+point_Y_s, point_X:point_X+point_X_s].reshape(1,point_Y_s,point_X_s,19)\n",
    "               \n",
    "                X_Patch_resize = resize(x_PATCH, (IMG_H, IMG_W), anti_aliasing=False)\n",
    "                Y_Patch_resize = resize(y_PATCH, (1,IMG_H, IMG_W), anti_aliasing=False)\n",
    "                \n",
    "                real_patch_resize = resize(real_patch, (IMG_H, IMG_W), anti_aliasing=False)\n",
    "                \n",
    "                X_Patch_resize = np.rollaxis(X_Patch_resize, axis = -1).reshape(1,3,IMG_H,IMG_W)\n",
    "                X_Patch_resize = torch.from_numpy(X_Patch_resize).float().to(device)\n",
    "              \n",
    "                \n",
    "                output = self.model(Variable(X_Patch_resize).cuda())\n",
    "                output = nn.functional.softmax(output, dim=1)\n",
    "                output=output.cpu().data[0].numpy()\n",
    "                y_patch_out = keras_out(output)\n",
    "                \n",
    "                SE_main = self_entropy(Y_Patch_resize)\n",
    "                SE_patch = self_entropy(y_patch_out)\n",
    "                \n",
    "                diff = (np.mean(SE_patch) - np.mean(SE_main))\n",
    "                \n",
    "                \n",
    "                \n",
    "                rl_patch.append(real_patch_resize)\n",
    "                se_Main.append(SE_main)\n",
    "                se_Patch.append(SE_patch)\n",
    "                se_diff.append(diff)\n",
    "                \n",
    "            se_diff = np.array(se_diff)\n",
    "            arg_max =np.argmax(se_diff)\n",
    "            maxi = np.max(se_diff)\n",
    "            print(maxi)\n",
    "            \n",
    "            Plot_img(rl_patch[arg_max])\n",
    "#             print(\"********Self entropy real*************\")\n",
    "#             plt.imshow(se_Main[arg_max].reshape(IMG_H,IMG_W),interpolation='nearest')\n",
    "#             plt.grid(False)\n",
    "#             plt.axis('off')\n",
    "#             plt.show()\n",
    "\n",
    "            print(\"******** patch Prediction*************\")\n",
    "            a =np.argmax(y_patch_out.T,axis=0)\n",
    "            true_lab = visualize(a.T.reshape((IMG_H,IMG_W)), False)\n",
    "            Plot_img(true_lab)\n",
    "            \n",
    "            print(\"********Self entropy patch*************\")\n",
    "            plt.imshow(se_Patch[arg_max].reshape(IMG_H,IMG_W),interpolation='nearest')\n",
    "            plt.grid(False)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            print(\"######################################################\")\n",
    "        \n",
    "           \n",
    "                \n",
    "\n",
    "            \n",
    "    def Analyze_class_frequency(self,num_of_samples ):\n",
    "        self.args.data_label_folder_target = None\n",
    "        self.args.shuffel_ = False\n",
    "        self.args.data_dir_target = root_base +'/dataset/cityscapes'\n",
    "        self.args.data_list_target = sorted_list\n",
    "        self.model.eval()\n",
    "        self.model.cuda()    \n",
    "        \n",
    "        targetloader = CreateTrgDataLoader(self.args)\n",
    "        \n",
    "        print(\"***********Testing Pseudo labels***********\")\n",
    "        \n",
    "        class_freq = 0\n",
    "        \n",
    "        for index, batch in enumerate(targetloader):\n",
    "            \n",
    "            if(index > num_of_samples):\n",
    "                break\n",
    "            \n",
    "            image, _, name, rl_img = batch\n",
    "            output = self.model(Variable(image).cuda())\n",
    "            output = nn.functional.softmax(output, dim=1)\n",
    "            rl_img = rl_img.cpu().data[0].numpy()/255.0\n",
    "            output=output.cpu().data[0].numpy()\n",
    "            Y_p = keras_out(output)    # later delete this line man\n",
    "            \n",
    "            image=image.cpu().data[0].numpy()\n",
    "            image = np.rollaxis(image, axis = -1)\n",
    "            image = np.rollaxis(image, axis = -1)\n",
    "            Y_pred = keras_out(output)\n",
    "            \n",
    "            class_are =   np.mean(Y_pred,axis = (0,1,2))\n",
    "            \n",
    "            class_freq += class_are\n",
    "        \n",
    "        return class_freq/num_of_samples\n",
    "            \n",
    "            \n",
    "        \n",
    "                \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yvBB1GsqQqKE"
   },
   "outputs": [],
   "source": [
    "# Base.sorting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4QnTVbtQqKJ"
   },
   "outputs": [],
   "source": [
    "entropy_th = 0.4\n",
    "patches = 5\n",
    "balance_  = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AaWz3I2BQqKN"
   },
   "outputs": [],
   "source": [
    "ana =Analysis(model_initl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PpggcLTQqKQ"
   },
   "outputs": [],
   "source": [
    "ana.Final_image_results( 82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Chtf0iO7QqKT"
   },
   "source": [
    "block diagram image select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCUmQsTzQqKU"
   },
   "outputs": [],
   "source": [
    "ana.Pseudo_labels_analysis(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vufI0XDDQqKa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NxRJwBUQqKd"
   },
   "outputs": [],
   "source": [
    "ana.Pseudo_labels_analysis_2(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "llz_raCUQqKf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ana.Pseudo_labels_analysis_2(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-knp3uPCQqKg"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class_=ana.Analyze_class_frequency(100\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVWc7eTCQqKi"
   },
   "outputs": [],
   "source": [
    "class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lv4G7RKjQqKk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KtMFQPQPQqKp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fI-1NP9gQqKs"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWrWdhbWQqKv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oXugA_9LQqKw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ssRR-f-nQqK0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vZPwpOhQqK6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHxRhLRRQqK7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0u9REzxQqK9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sHEUw9WJQqLA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqGN310DQqLH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BzRlkU9ZQqLK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exp_7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
